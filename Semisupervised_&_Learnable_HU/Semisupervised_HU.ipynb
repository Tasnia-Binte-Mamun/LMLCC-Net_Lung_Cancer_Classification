{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:05:43.544938Z",
     "iopub.status.busy": "2024-08-10T16:05:43.544631Z",
     "iopub.status.idle": "2024-08-10T16:05:55.788691Z",
     "shell.execute_reply": "2024-08-10T16:05:55.787500Z",
     "shell.execute_reply.started": "2024-08-10T16:05:43.544911Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install nibabel\n",
    "!pip install seaborn\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:05:55.791094Z",
     "iopub.status.busy": "2024-08-10T16:05:55.790805Z",
     "iopub.status.idle": "2024-08-10T16:06:12.428638Z",
     "shell.execute_reply": "2024-08-10T16:06:12.427902Z",
     "shell.execute_reply.started": "2024-08-10T16:05:55.791042Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,Input\n",
    "from keras.layers import Convolution3D,Conv3D,Add,concatenate, MaxPool3D,add, Convolution2D,BatchNormalization, GlobalAveragePooling3D, ZeroPadding3D\n",
    "from tensorflow.keras.layers import Input, Conv3D, BatchNormalization, MaxPool3D, Flatten, Dense, Dropout, concatenate, Lambda, Layer\n",
    "from keras import backend as K\n",
    "import cv2\n",
    "import operator\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from scipy.ndimage import rotate\n",
    "import random\n",
    "import nibabel as nib\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from matplotlib import animation, rc\n",
    "from scipy.ndimage import rotate\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import KFold, StratifiedKFold,train_test_split\n",
    "from scipy.ndimage import zoom\n",
    "from matplotlib.patches import PathPatch, Rectangle\n",
    "from IPython.display import HTML\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv3D, BatchNormalization, MaxPool3D, Flatten, Dense, Dropout, concatenate, Lambda, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:06:12.430304Z",
     "iopub.status.busy": "2024-08-10T16:06:12.429771Z",
     "iopub.status.idle": "2024-08-10T16:06:20.474886Z",
     "shell.execute_reply": "2024-08-10T16:06:20.473686Z",
     "shell.execute_reply.started": "2024-08-10T16:06:12.430270Z"
    }
   },
   "outputs": [],
   "source": [
    "# Enable TPU\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print(\"Device:\", tpu.master())\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:06:20.477307Z",
     "iopub.status.busy": "2024-08-10T16:06:20.477032Z",
     "iopub.status.idle": "2024-08-10T16:06:20.490279Z",
     "shell.execute_reply": "2024-08-10T16:06:20.489409Z",
     "shell.execute_reply.started": "2024-08-10T16:06:20.477280Z"
    }
   },
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(32,(3,3,3), activation='relu', kernel_initializer='he_uniform', padding='same',input_shape=(32,32,32,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv3D(32, (3, 3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool3D((2, 2,2)))\n",
    "    #model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Conv3D(64, (3, 3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv3D(64, (3, 3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool3D((2, 2,2)))\n",
    "    #model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv3D(128, (3, 3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv3D(128, (3, 3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool3D((2, 2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv3D(128, (3, 3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv3D(128, (3, 3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv3D(128, (3, 3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv3D(128, (3, 3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool3D((2, 2,2)))\n",
    "\n",
    "    model.add(Conv3D(256, (3, 3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv3D(256, (3, 3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(MaxPool3D((2, 2,2))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(8, activation='relu', kernel_initializer='he_uniform'))\n",
    "\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer='he_uniform'));\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:06:20.491437Z",
     "iopub.status.busy": "2024-08-10T16:06:20.491195Z",
     "iopub.status.idle": "2024-08-10T16:06:20.510137Z",
     "shell.execute_reply": "2024-08-10T16:06:20.509365Z",
     "shell.execute_reply.started": "2024-08-10T16:06:20.491412Z"
    }
   },
   "outputs": [],
   "source": [
    "BS=68 # batch size\n",
    "RS= 0 #random state\n",
    "E = 200 #epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:06:20.511374Z",
     "iopub.status.busy": "2024-08-10T16:06:20.511125Z",
     "iopub.status.idle": "2024-08-10T16:06:20.521309Z",
     "shell.execute_reply": "2024-08-10T16:06:20.520503Z",
     "shell.execute_reply.started": "2024-08-10T16:06:20.511345Z"
    }
   },
   "outputs": [],
   "source": [
    "def aug_rotate(x):\n",
    "\n",
    "    rotated_slices = []\n",
    "    for slice_idx in range(x.shape[2]):\n",
    "        slice_data = x[:, :, slice_idx]  # Extract a single slice\n",
    "        rotated_slice = rotate(slice_data, angle=angles[j], reshape=False, mode='nearest')\n",
    "        rotated_slices.append(rotated_slice)\n",
    "\n",
    "    # Create a new NIfTI image from the rotated slices\n",
    "    rotated_img_data = np.stack(rotated_slices, axis=-1)\n",
    "    # Create a new NIfTI image using the header information from the original image\n",
    "    rotated_nifti = nib.Nifti1Image(rotated_img_data, img.affine)\n",
    "    \n",
    "    return rotated_nifti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:06:20.522495Z",
     "iopub.status.busy": "2024-08-10T16:06:20.522281Z",
     "iopub.status.idle": "2024-08-10T16:06:21.779618Z",
     "shell.execute_reply": "2024-08-10T16:06:21.778609Z",
     "shell.execute_reply.started": "2024-08-10T16:06:20.522472Z"
    }
   },
   "outputs": [],
   "source": [
    "luna_df = pd.read_excel('/kaggle/input/spie-cropped-resampled-dataset/final_Luna16.xlsx')\n",
    "column_luna = 'malignancy'\n",
    "luna_series=luna_df['Series Uid'].tolist()\n",
    "\n",
    "luna_folder = '/kaggle/input/spie-cropped-resampled-dataset/Luna_16_cropped_resampled/Luna_16_cropped_resampled'  \n",
    "luna = []\n",
    "for i in luna_series:\n",
    "    nii_file_path = os.path.join(luna_folder, f'{i}.nii')  # Assuming NII files have the extension '.nii'\n",
    "    \n",
    "    if os.path.exists(nii_file_path):\n",
    "        luna.append(i)\n",
    "luna=np.array(luna)\n",
    "\n",
    "print(luna.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA PREPARATION FOR SSL(UNLABELED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:06:21.781110Z",
     "iopub.status.busy": "2024-08-10T16:06:21.780789Z",
     "iopub.status.idle": "2024-08-10T16:06:21.889029Z",
     "shell.execute_reply": "2024-08-10T16:06:21.888117Z",
     "shell.execute_reply.started": "2024-08-10T16:06:21.781057Z"
    }
   },
   "outputs": [],
   "source": [
    "luna_semi_df = pd.read_excel('/kaggle/input/spie-cropped-resampled-dataset/unlabeled_data_Luna.xlsx')\n",
    "#column_name = 'malignancy'\n",
    "col_scan='Series Uid'\n",
    "\n",
    "luna_semi_scan = luna_semi_df[col_scan].tolist()\n",
    "\n",
    "scans1=[]\n",
    "for i in luna_semi_scan:\n",
    "    scans1.append(i)\n",
    "\n",
    "luna_semi=np.array(scans1)\n",
    "print(len(luna_semi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:06:21.890494Z",
     "iopub.status.busy": "2024-08-10T16:06:21.890189Z",
     "iopub.status.idle": "2024-08-10T16:06:28.498628Z",
     "shell.execute_reply": "2024-08-10T16:06:28.497635Z",
     "shell.execute_reply.started": "2024-08-10T16:06:21.890465Z"
    }
   },
   "outputs": [],
   "source": [
    "datas_luna_semi=[]\n",
    "scans_luna_semi=[]\n",
    "\n",
    "for i in luna_semi:\n",
    "    img_files = glob.glob(os.path.join(\"/kaggle/input/spie-cropped-resampled-dataset/Luna_16_cropped_resampled/Luna_16_cropped_resampled/\",i +\"*.nii\"))\n",
    "\n",
    "    for img_file in img_files:\n",
    "        img = nib.load(img_file)\n",
    "        data = img.get_fdata()\n",
    "        datas_luna_semi.append(data)\n",
    "        scans_luna_semi.append(i)\n",
    "\n",
    "X_luna_semi = np.array(datas_luna_semi)\n",
    "z_luna_semi= np.array(scans_luna_semi)\n",
    "\n",
    "print(X_luna_semi.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIXED TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:06:28.502140Z",
     "iopub.status.busy": "2024-08-10T16:06:28.501772Z",
     "iopub.status.idle": "2024-08-10T16:06:28.508459Z",
     "shell.execute_reply": "2024-08-10T16:06:28.507614Z",
     "shell.execute_reply.started": "2024-08-10T16:06:28.502105Z"
    }
   },
   "outputs": [],
   "source": [
    "luna_initial,luna_fixed_test = train_test_split(luna, test_size=0.2, random_state=RS)\n",
    "\n",
    "z_luna_fixed_test=np.array(luna_fixed_test)\n",
    "z_luna_initial=np.array(luna_initial)\n",
    "\n",
    "print(luna_initial.shape)# initial train\n",
    "print(luna_fixed_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:06:28.509739Z",
     "iopub.status.busy": "2024-08-10T16:06:28.509480Z",
     "iopub.status.idle": "2024-08-10T16:06:28.570056Z",
     "shell.execute_reply": "2024-08-10T16:06:28.569036Z",
     "shell.execute_reply.started": "2024-08-10T16:06:28.509712Z"
    }
   },
   "outputs": [],
   "source": [
    "luna_fixed_test_df = pd.DataFrame({'luna fixed test set': luna_fixed_test})\n",
    "luna_initial_df = pd.DataFrame({'luna initial set': luna_initial})\n",
    "\n",
    "\n",
    "# Create a new DataFrame with the matched scans\n",
    "matched_df = pd.DataFrame({'luna fixed test set': luna_fixed_test_df['luna fixed test set'],\n",
    "                           'luna initial set': luna_initial_df['luna initial set'],})\n",
    "\n",
    "\n",
    "\n",
    "matched_df.to_excel('/kaggle/working/scans_for_semisupervised.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:06:28.571607Z",
     "iopub.status.busy": "2024-08-10T16:06:28.571313Z",
     "iopub.status.idle": "2024-08-10T16:06:29.694804Z",
     "shell.execute_reply": "2024-08-10T16:06:29.693613Z",
     "shell.execute_reply.started": "2024-08-10T16:06:28.571579Z"
    }
   },
   "outputs": [],
   "source": [
    "datas_luna_fixed_test=[]\n",
    "labels_luna_fixed_test=[]\n",
    "scans_luna_fixed_test=[]\n",
    "\n",
    "for i in luna_fixed_test:\n",
    "    lab = luna_df.loc[luna_df['Series Uid'] == i, 'malignancy'].values[0]\n",
    "    img_files = glob.glob(os.path.join(\"/kaggle/input/spie-cropped-resampled-dataset/Luna_16_cropped_resampled/Luna_16_cropped_resampled/\",i +\"*.nii\"))\n",
    "\n",
    "    for img_file in img_files:\n",
    "        img = nib.load(img_file)\n",
    "        data = img.get_fdata()\n",
    "        datas_luna_fixed_test.append(data)\n",
    "        labels_luna_fixed_test.append(lab)\n",
    "        scans_luna_fixed_test.append(i)\n",
    "\n",
    "X_luna_fixed_test = np.array(datas_luna_fixed_test)\n",
    "y_luna_fixed_test = np.array(labels_luna_fixed_test)\n",
    "z_luna_fixed_test= np.array(scans_luna_fixed_test)\n",
    "\n",
    "print(X_luna_fixed_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  FIRST TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:06:29.696306Z",
     "iopub.status.busy": "2024-08-10T16:06:29.696007Z",
     "iopub.status.idle": "2024-08-10T16:06:29.702044Z",
     "shell.execute_reply": "2024-08-10T16:06:29.701183Z",
     "shell.execute_reply.started": "2024-08-10T16:06:29.696280Z"
    }
   },
   "outputs": [],
   "source": [
    "z_train1, z_val1 = train_test_split(z_luna_initial, test_size=0.2, random_state=RS)\n",
    "print(z_train1.shape,z_val1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:06:29.703467Z",
     "iopub.status.busy": "2024-08-10T16:06:29.703233Z",
     "iopub.status.idle": "2024-08-10T16:07:04.624051Z",
     "shell.execute_reply": "2024-08-10T16:07:04.623053Z",
     "shell.execute_reply.started": "2024-08-10T16:06:29.703443Z"
    }
   },
   "outputs": [],
   "source": [
    "angles = [0, 45, 90, 135, 180, 225, 270, 315]\n",
    "\n",
    "\n",
    "datas_train = []\n",
    "labels_train=[]\n",
    "\n",
    "datas_val = []\n",
    "labels_val=[]\n",
    "\n",
    "for i in z_train1:\n",
    "    lab = luna_df.loc[luna_df['Series Uid'] == i, 'malignancy'].values[0]\n",
    "    img_files = glob.glob(os.path.join(\"/kaggle/input/spie-cropped-resampled-dataset/Luna_16_cropped_resampled/Luna_16_cropped_resampled/\",i +\"*.nii\"))\n",
    "    for img_file in img_files:\n",
    "        img = nib.load(img_file)\n",
    "        data = img.get_fdata()\n",
    "        \n",
    "        for j in range(len(angles)):\n",
    "            rotated_nifti = aug_rotate(data)\n",
    "            datas_train.append(rotated_nifti.get_fdata())\n",
    "            labels_train.append(lab)\n",
    "            \n",
    "            \n",
    "for i in z_val1:\n",
    "    lab = luna_df.loc[luna_df['Series Uid'] == i, 'malignancy'].values[0]\n",
    "    img_files = glob.glob(os.path.join(\"/kaggle/input/spie-cropped-resampled-dataset/Luna_16_cropped_resampled/Luna_16_cropped_resampled/\",i +\"*.nii\"))\n",
    "    for img_file in img_files:\n",
    "        img = nib.load(img_file)\n",
    "        data = img.get_fdata()\n",
    "        datas_val.append(data)\n",
    "        labels_val.append(lab)\n",
    "\n",
    "\n",
    "X_train1=np.array(datas_train)\n",
    "y_train1=np.array(labels_train)\n",
    "\n",
    "X_val1=np.array(datas_val)\n",
    "y_val1=np.array(labels_val)        \n",
    "\n",
    "print(y_train1.shape,sum(y_train1))\n",
    "print(y_val1.shape,sum(y_val1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:07:04.625846Z",
     "iopub.status.busy": "2024-08-10T16:07:04.625500Z",
     "iopub.status.idle": "2024-08-10T16:13:50.813939Z",
     "shell.execute_reply": "2024-08-10T16:13:50.812776Z",
     "shell.execute_reply.started": "2024-08-10T16:07:04.625812Z"
    }
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model=define_model()\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.001,\n",
    "        patience=5,\n",
    "        min_lr=1e-6)\n",
    "\n",
    "# Define the model checkpoint callback to save the best model\n",
    "checkpoint_callback = ModelCheckpoint('semiSupervised_HU1.h5', monitor='val_accuracy',save_best_only=True)\n",
    "\n",
    "BATCH_SIZE_TPU = BS * strategy.num_replicas_in_sync\n",
    "# Fit data to model\n",
    "history = model.fit(X_train1, y_train1, validation_data=(X_val1, y_val1), epochs=E, batch_size=BATCH_SIZE_TPU,callbacks=[lr_callback,checkpoint_callback],verbose=0)\n",
    "\n",
    "\n",
    "# Evaluate the model - report accuracy and capture it into a list for future reporting\n",
    "best_model1 = tf.keras.models.load_model('semiSupervised_HU1.h5')\n",
    "\n",
    "loss1, accuracy1 = best_model1.evaluate(X_luna_fixed_test, y_luna_fixed_test)   \n",
    "\n",
    "\n",
    "print(f'Luna Accuracy: {accuracy1}')\n",
    "print('luna loss: ',loss1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:13:50.815470Z",
     "iopub.status.busy": "2024-08-10T16:13:50.815184Z",
     "iopub.status.idle": "2024-08-10T16:13:53.085569Z",
     "shell.execute_reply": "2024-08-10T16:13:53.084700Z",
     "shell.execute_reply.started": "2024-08-10T16:13:50.815440Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = best_model1.predict(X_luna_fixed_test)\n",
    "predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Generate the classification report\n",
    "class_names = list(['benign','malignant'])\n",
    "report1 = classification_report(y_luna_fixed_test, predicted_classes , target_names=class_names)\n",
    "print(\"Classification Report:\\n\", report1)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm1 = confusion_matrix(y_luna_fixed_test, predicted_classes )\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm1, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "auc = roc_auc_score(y_luna_fixed_test, predictions)\n",
    "print(f'AUC: {auc}')\n",
    "\n",
    "#---------------------------------------------------------\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:13:53.086973Z",
     "iopub.status.busy": "2024-08-10T16:13:53.086680Z",
     "iopub.status.idle": "2024-08-10T16:13:53.157960Z",
     "shell.execute_reply": "2024-08-10T16:13:53.157097Z",
     "shell.execute_reply.started": "2024-08-10T16:13:53.086942Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(X_luna_fixed_test,open('test_x','wb'))\n",
    "pickle.dump(y_luna_fixed_test,open('test_y','wb'))\n",
    "pickle.dump(z_luna_fixed_test,open('test_z','wb'))\n",
    "\n",
    "\n",
    "pickle.dump(X_val1,open('val1_x','wb'))\n",
    "pickle.dump(y_val1,open('val1_y','wb'))\n",
    "pickle.dump(z_val1,open('val1_z','wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prediction from unbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:13:53.159176Z",
     "iopub.status.busy": "2024-08-10T16:13:53.158914Z",
     "iopub.status.idle": "2024-08-10T16:13:57.819174Z",
     "shell.execute_reply": "2024-08-10T16:13:57.818205Z",
     "shell.execute_reply.started": "2024-08-10T16:13:53.159149Z"
    }
   },
   "outputs": [],
   "source": [
    "correct_predictions1 = []\n",
    "incorrect_predictions1 = []\n",
    "\n",
    "predictions = best_model1.predict(X_luna_semi)\n",
    "for i in range(len(X_luna_semi)):\n",
    "    if predictions[i] > 0.9:\n",
    "        correct_predictions1.append((z_luna_semi[i], 1))\n",
    "    elif predictions[i] < 0.1:\n",
    "        correct_predictions1.append((z_luna_semi[i], 0))\n",
    "    else:\n",
    "        incorrect_predictions1.append(z_luna_semi[i])\n",
    "\n",
    "print(len(incorrect_predictions1),len(correct_predictions1))\n",
    "        \n",
    "# Create a DataFrame with 'scan' and 'malignancy' columns\n",
    "df_correct_predictions1 = pd.DataFrame(correct_predictions1, columns=['scan', 'malignancy'])\n",
    "\n",
    "scan_identifiers_z_train2 = np.array([item[0] for item in correct_predictions1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:13:57.820895Z",
     "iopub.status.busy": "2024-08-10T16:13:57.820327Z",
     "iopub.status.idle": "2024-08-10T16:14:35.298189Z",
     "shell.execute_reply": "2024-08-10T16:14:35.297081Z",
     "shell.execute_reply.started": "2024-08-10T16:13:57.820861Z"
    }
   },
   "outputs": [],
   "source": [
    "datas_train = []\n",
    "labels_train=[]\n",
    "scans_train=[]\n",
    "\n",
    "datas_val = []\n",
    "labels_val=[]\n",
    "scans_val=[]\n",
    "\n",
    "\n",
    "\n",
    "for i in scan_identifiers_z_train2:\n",
    "    lab = df_correct_predictions1.loc[df_correct_predictions1['scan'] == i, 'malignancy'].values[0]\n",
    "    img_files = glob.glob(os.path.join(\"/kaggle/input/spie-cropped-resampled-dataset/Luna_16_cropped_resampled/Luna_16_cropped_resampled/\", i + \"*.nii\"))\n",
    "\n",
    "    scans_train.append(i)\n",
    "    for img_file in img_files:\n",
    "        img = nib.load(img_file)\n",
    "        data = img.get_fdata()\n",
    "\n",
    "        for j in range(len(angles)):\n",
    "            rotated_nifti = aug_rotate(data)\n",
    "            datas_train.append(rotated_nifti.get_fdata())\n",
    "            labels_train.append(lab)\n",
    "\n",
    "\n",
    "\n",
    "X_train2=np.array(datas_train)\n",
    "y_train2=np.array(labels_train)\n",
    "z_train2=np.array(scans_train)\n",
    "\n",
    "print(z_train2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:14:35.299853Z",
     "iopub.status.busy": "2024-08-10T16:14:35.299526Z",
     "iopub.status.idle": "2024-08-10T16:14:35.861371Z",
     "shell.execute_reply": "2024-08-10T16:14:35.860194Z",
     "shell.execute_reply.started": "2024-08-10T16:14:35.299819Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train1, X_train2))\n",
    "y_train = np.concatenate((y_train1, y_train2))\n",
    "z_train = np.concatenate((z_train1, z_train2))\n",
    "print(z_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## second train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:14:35.862948Z",
     "iopub.status.busy": "2024-08-10T16:14:35.862657Z",
     "iopub.status.idle": "2024-08-10T16:24:28.957742Z",
     "shell.execute_reply": "2024-08-10T16:24:28.956600Z",
     "shell.execute_reply.started": "2024-08-10T16:14:35.862921Z"
    }
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model=define_model()\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.001,\n",
    "        patience=5,\n",
    "        min_lr=1e-6)\n",
    "\n",
    "# Define the model checkpoint callback to save the best model\n",
    "checkpoint_callback = ModelCheckpoint('semiSupervised_HU2.h5', monitor='val_accuracy',save_best_only=True)\n",
    "\n",
    "BATCH_SIZE_TPU = BS * strategy.num_replicas_in_sync\n",
    "# Fit data to model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val1, y_val1), epochs=E, batch_size=BATCH_SIZE_TPU,callbacks=[lr_callback,checkpoint_callback],verbose=0)\n",
    "\n",
    "\n",
    "# Evaluate the model - report accuracy and capture it into a list for future reporting\n",
    "best_model2 = tf.keras.models.load_model('semiSupervised_HU2.h5')\n",
    "\n",
    "loss2, accuracy2 = best_model2.evaluate(X_luna_fixed_test, y_luna_fixed_test)   \n",
    "\n",
    "\n",
    "print(f'Luna Accuracy: {accuracy2}')\n",
    "print('luna loss: ',loss2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:24:28.959412Z",
     "iopub.status.busy": "2024-08-10T16:24:28.959106Z",
     "iopub.status.idle": "2024-08-10T16:24:30.698979Z",
     "shell.execute_reply": "2024-08-10T16:24:30.697901Z",
     "shell.execute_reply.started": "2024-08-10T16:24:28.959381Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = best_model2.predict(X_luna_fixed_test)\n",
    "predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Generate the classification report\n",
    "class_names = list(['benign','malignant'])\n",
    "report2 = classification_report(y_luna_fixed_test, predicted_classes , target_names=class_names)\n",
    "print(\"Classification Report:\\n\", report2)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm2 = confusion_matrix(y_luna_fixed_test, predicted_classes )\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm2, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "auc = roc_auc_score(y_luna_fixed_test, predictions)\n",
    "print(f'AUC: {auc}')\n",
    "#---------------------------------------------------------\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unpredicted data after 2nd train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:24:30.700500Z",
     "iopub.status.busy": "2024-08-10T16:24:30.700239Z",
     "iopub.status.idle": "2024-08-10T16:24:31.814212Z",
     "shell.execute_reply": "2024-08-10T16:24:31.813212Z",
     "shell.execute_reply.started": "2024-08-10T16:24:30.700473Z"
    }
   },
   "outputs": [],
   "source": [
    "datas_semi = []\n",
    "labels_semi = []\n",
    "scans_semi = []\n",
    "\n",
    "for i in incorrect_predictions1:\n",
    "        img_files = glob.glob(os.path.join(\"/kaggle/input/spie-cropped-resampled-dataset/Luna_16_cropped_resampled/Luna_16_cropped_resampled/\", i + \"*.nii\"))\n",
    "\n",
    "        for img_file in img_files:\n",
    "            img = nib.load(img_file)\n",
    "            data = img.get_fdata()\n",
    "            datas_semi.append(data)\n",
    "            scans_semi.append(i)\n",
    "\n",
    "X_semi2 = np.array(datas_semi)\n",
    "z_semi2 = np.array(scans_semi)\n",
    "\n",
    "print(X_semi2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:24:31.815497Z",
     "iopub.status.busy": "2024-08-10T16:24:31.815242Z",
     "iopub.status.idle": "2024-08-10T16:24:33.496126Z",
     "shell.execute_reply": "2024-08-10T16:24:33.494809Z",
     "shell.execute_reply.started": "2024-08-10T16:24:31.815472Z"
    }
   },
   "outputs": [],
   "source": [
    "correct_predictions2 = []\n",
    "incorrect_predictions2 = []\n",
    "\n",
    "predictions = best_model2.predict(X_semi2)\n",
    "for i in range(len(X_semi2)):\n",
    "    if predictions[i] > 0.9:\n",
    "        correct_predictions2.append((z_luna_semi[i], 1))\n",
    "    elif predictions[i] < 0.1:\n",
    "        correct_predictions2.append((z_luna_semi[i], 0))\n",
    "    else:\n",
    "        incorrect_predictions2.append(z_luna_semi[i])\n",
    "\n",
    "print(len(incorrect_predictions2),len(correct_predictions2))\n",
    "\n",
    "# Create a DataFrame with 'scan' and 'malignancy' columns\n",
    "df_correct_predictions2 = pd.DataFrame(correct_predictions2, columns=['scan', 'malignancy'])\n",
    "\n",
    "\n",
    "scan_identifiers_z_train3 = np.array([item[0] for item in correct_predictions2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:24:33.497783Z",
     "iopub.status.busy": "2024-08-10T16:24:33.497448Z",
     "iopub.status.idle": "2024-08-10T16:24:44.415266Z",
     "shell.execute_reply": "2024-08-10T16:24:44.414115Z",
     "shell.execute_reply.started": "2024-08-10T16:24:33.497751Z"
    }
   },
   "outputs": [],
   "source": [
    "datas_train = []\n",
    "labels_train=[]\n",
    "scans_train=[]\n",
    "\n",
    "datas_val = []\n",
    "labels_val=[]\n",
    "scans_val=[]\n",
    "\n",
    "\n",
    "\n",
    "for i in scan_identifiers_z_train3:\n",
    "    lab = df_correct_predictions2.loc[df_correct_predictions2['scan'] == i, 'malignancy'].values[0]\n",
    "    img_files = glob.glob(os.path.join(\"/kaggle/input/spie-cropped-resampled-dataset/Luna_16_cropped_resampled/Luna_16_cropped_resampled/\", i + \"*.nii\"))\n",
    "\n",
    "    scans_train.append(i)\n",
    "    for img_file in img_files:\n",
    "        img = nib.load(img_file)\n",
    "        data = img.get_fdata()\n",
    "\n",
    "        for j in range(len(angles)):\n",
    "            rotated_nifti = aug_rotate(data)\n",
    "            datas_train.append(rotated_nifti.get_fdata())\n",
    "            labels_train.append(lab)\n",
    "\n",
    "\n",
    "\n",
    "X_train3=np.array(datas_train)\n",
    "y_train3=np.array(labels_train)\n",
    "z_train3=np.array(scans_train)\n",
    "\n",
    "print(z_train3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:24:44.416859Z",
     "iopub.status.busy": "2024-08-10T16:24:44.416544Z",
     "iopub.status.idle": "2024-08-10T16:24:45.084476Z",
     "shell.execute_reply": "2024-08-10T16:24:45.083339Z",
     "shell.execute_reply.started": "2024-08-10T16:24:44.416827Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train1, X_train2 , X_train3))\n",
    "y_train = np.concatenate((y_train1, y_train2 , y_train3))\n",
    "z_train = np.concatenate((z_train1, z_train2 , z_train3))\n",
    "print(z_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3rd train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:24:45.085829Z",
     "iopub.status.busy": "2024-08-10T16:24:45.085559Z",
     "iopub.status.idle": "2024-08-10T16:35:07.212353Z",
     "shell.execute_reply": "2024-08-10T16:35:07.211246Z",
     "shell.execute_reply.started": "2024-08-10T16:24:45.085803Z"
    }
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model=define_model()\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.001,\n",
    "        patience=5,\n",
    "        min_lr=1e-6)\n",
    "\n",
    "# Define the model checkpoint callback to save the best model\n",
    "checkpoint_callback = ModelCheckpoint('semiSupervised_HU3.h5', monitor='val_accuracy',save_best_only=True)\n",
    "\n",
    "BATCH_SIZE_TPU = BS * strategy.num_replicas_in_sync\n",
    "# Fit data to model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val1, y_val1), epochs=E, batch_size=BATCH_SIZE_TPU,callbacks=[lr_callback,checkpoint_callback],verbose=0)\n",
    "\n",
    "\n",
    "# Evaluate the model - report accuracy and capture it into a list for future reporting\n",
    "best_model3 = tf.keras.models.load_model('semiSupervised_HU3.h5')\n",
    "\n",
    "loss3, accuracy3 = best_model3.evaluate(X_luna_fixed_test, y_luna_fixed_test)   \n",
    "\n",
    "print(f'Luna Accuracy: {accuracy3}')\n",
    "print('luna loss: ',loss3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:35:07.219292Z",
     "iopub.status.busy": "2024-08-10T16:35:07.218956Z",
     "iopub.status.idle": "2024-08-10T16:35:09.058118Z",
     "shell.execute_reply": "2024-08-10T16:35:09.057288Z",
     "shell.execute_reply.started": "2024-08-10T16:35:07.219259Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = best_model3.predict(X_luna_fixed_test)\n",
    "predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Generate the classification report\n",
    "class_names = list(['benign','malignant'])\n",
    "report3 = classification_report(y_luna_fixed_test, predicted_classes , target_names=class_names)\n",
    "print(\"Classification Report:\\n\", report3)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm3 = confusion_matrix(y_luna_fixed_test, predicted_classes )\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm3, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "auc = roc_auc_score(y_luna_fixed_test, predictions)\n",
    "print(f'AUC: {auc}')\n",
    "#---------------------------------------------------------\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unpredicted data after 3rd train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:35:09.059446Z",
     "iopub.status.busy": "2024-08-10T16:35:09.059172Z",
     "iopub.status.idle": "2024-08-10T16:35:09.567178Z",
     "shell.execute_reply": "2024-08-10T16:35:09.566286Z",
     "shell.execute_reply.started": "2024-08-10T16:35:09.059418Z"
    }
   },
   "outputs": [],
   "source": [
    "datas_semi = []\n",
    "labels_semi = []\n",
    "scans_semi = []\n",
    "\n",
    "for i in incorrect_predictions2:\n",
    "        img_files = glob.glob(os.path.join(\"/kaggle/input/spie-cropped-resampled-dataset/Luna_16_cropped_resampled/Luna_16_cropped_resampled/\", i + \"*.nii\"))\n",
    "\n",
    "        for img_file in img_files:\n",
    "            img = nib.load(img_file)\n",
    "            data = img.get_fdata()\n",
    "            datas_semi.append(data)\n",
    "            scans_semi.append(i)\n",
    "\n",
    "X_semi3 = np.array(datas_semi)\n",
    "z_semi3 = np.array(scans_semi)\n",
    "\n",
    "print(X_semi3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:35:09.568514Z",
     "iopub.status.busy": "2024-08-10T16:35:09.568243Z",
     "iopub.status.idle": "2024-08-10T16:35:10.284185Z",
     "shell.execute_reply": "2024-08-10T16:35:10.283243Z",
     "shell.execute_reply.started": "2024-08-10T16:35:09.568486Z"
    }
   },
   "outputs": [],
   "source": [
    "correct_predictions3 = []\n",
    "incorrect_predictions3 = []\n",
    "\n",
    "predictions = best_model3.predict(X_semi3)\n",
    "for i in range(len(X_semi3)):\n",
    "    if predictions[i] > 0.9:\n",
    "        correct_predictions3.append((z_luna_semi[i], 1))\n",
    "    elif predictions[i] < 0.1:\n",
    "        correct_predictions3.append((z_luna_semi[i], 0))\n",
    "    else:\n",
    "        incorrect_predictions3.append(z_luna_semi[i])\n",
    "\n",
    "print(len(incorrect_predictions3),len(correct_predictions3))\n",
    "        \n",
    "# Create a DataFrame with 'scan' and 'malignancy' columns\n",
    "df_correct_predictions3 = pd.DataFrame(correct_predictions3, columns=['scan', 'malignancy'])\n",
    "\n",
    "print(df_correct_predictions3.shape)\n",
    "\n",
    "\n",
    "scan_identifiers_z_train4 = np.array([item[0] for item in correct_predictions3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:35:10.285650Z",
     "iopub.status.busy": "2024-08-10T16:35:10.285339Z",
     "iopub.status.idle": "2024-08-10T16:35:14.629794Z",
     "shell.execute_reply": "2024-08-10T16:35:14.628892Z",
     "shell.execute_reply.started": "2024-08-10T16:35:10.285617Z"
    }
   },
   "outputs": [],
   "source": [
    "datas_train = []\n",
    "labels_train=[]\n",
    "scans_train=[]\n",
    "\n",
    "datas_val = []\n",
    "labels_val=[]\n",
    "scans_val=[]\n",
    "\n",
    "\n",
    "\n",
    "for i in scan_identifiers_z_train4:\n",
    "    lab = df_correct_predictions3.loc[df_correct_predictions3['scan'] == i, 'malignancy'].values[0]\n",
    "    img_files = glob.glob(os.path.join(\"/kaggle/input/spie-cropped-resampled-dataset/Luna_16_cropped_resampled/Luna_16_cropped_resampled/\", i + \"*.nii\"))\n",
    "\n",
    "    scans_train.append(i)\n",
    "    for img_file in img_files:\n",
    "        img = nib.load(img_file)\n",
    "        data = img.get_fdata()\n",
    "\n",
    "        for j in range(len(angles)):\n",
    "            rotated_nifti = aug_rotate(data)\n",
    "            datas_train.append(rotated_nifti.get_fdata())\n",
    "            labels_train.append(lab)\n",
    "\n",
    "\n",
    "\n",
    "X_train4=np.array(datas_train)\n",
    "y_train4=np.array(labels_train)\n",
    "z_train4=np.array(scans_train)\n",
    "\n",
    "print(z_train4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T17:11:03.323269Z",
     "iopub.status.busy": "2024-08-10T17:11:03.322394Z",
     "iopub.status.idle": "2024-08-10T17:11:04.008470Z",
     "shell.execute_reply": "2024-08-10T17:11:04.007575Z",
     "shell.execute_reply.started": "2024-08-10T17:11:03.323229Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train1, X_train2 , X_train3 , X_train4))\n",
    "y_train = np.concatenate((y_train1, y_train2 , y_train3 , y_train4))\n",
    "z_train = np.concatenate((z_train1, z_train2 , z_train3 , z_train4))\n",
    "print(z_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4th train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T17:32:29.275937Z",
     "iopub.status.busy": "2024-08-10T17:32:29.275467Z",
     "iopub.status.idle": "2024-08-10T17:43:02.965372Z",
     "shell.execute_reply": "2024-08-10T17:43:02.964305Z",
     "shell.execute_reply.started": "2024-08-10T17:32:29.275893Z"
    }
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model=define_model()\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.001,\n",
    "        patience=5,\n",
    "        min_lr=1e-6)\n",
    "\n",
    "# Define the model checkpoint callback to save the best model\n",
    "checkpoint_callback = ModelCheckpoint('semiSupervised_HU4.h5', monitor='val_accuracy',save_best_only=True)\n",
    "\n",
    "BATCH_SIZE_TPU = BS * strategy.num_replicas_in_sync\n",
    "# Fit data to model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val1, y_val1), epochs=E, batch_size=BATCH_SIZE_TPU,callbacks=[lr_callback,checkpoint_callback],verbose=0)\n",
    "\n",
    "\n",
    "# Evaluate the model - report accuracy and capture it into a list for future reporting\n",
    "best_model4 = tf.keras.models.load_model('semiSupervised_HU4.h5')\n",
    "\n",
    "loss4, accuracy4 = best_model4.evaluate(X_luna_fixed_test, y_luna_fixed_test)   \n",
    "print(f'Luna Accuracy: {accuracy4}')\n",
    "print('luna loss: ',loss4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T17:43:26.538936Z",
     "iopub.status.busy": "2024-08-10T17:43:26.537610Z",
     "iopub.status.idle": "2024-08-10T17:43:28.294027Z",
     "shell.execute_reply": "2024-08-10T17:43:28.293222Z",
     "shell.execute_reply.started": "2024-08-10T17:43:26.538889Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = best_model4.predict(X_luna_fixed_test)\n",
    "predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Generate the classification report\n",
    "class_names = list(['benign','malignant'])\n",
    "report4 = classification_report(y_luna_fixed_test, predicted_classes , target_names=class_names)\n",
    "print(\"Classification Report:\\n\", report4)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm4 = confusion_matrix(y_luna_fixed_test, predicted_classes )\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm4, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "auc = roc_auc_score(y_luna_fixed_test, predictions)\n",
    "print(f'AUC: {auc}')\n",
    "#---------------------------------------------------------\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T17:43:31.778845Z",
     "iopub.status.busy": "2024-08-10T17:43:31.778147Z",
     "iopub.status.idle": "2024-08-10T17:43:32.107921Z",
     "shell.execute_reply": "2024-08-10T17:43:32.106834Z",
     "shell.execute_reply.started": "2024-08-10T17:43:31.778804Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(X_train4,open('train4_x','wb'))\n",
    "pickle.dump(y_train4,open('train4_y','wb'))\n",
    "pickle.dump(z_train4,open('train4_z','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unpredicted data after 4th train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T17:43:32.958642Z",
     "iopub.status.busy": "2024-08-10T17:43:32.958217Z",
     "iopub.status.idle": "2024-08-10T17:43:33.147346Z",
     "shell.execute_reply": "2024-08-10T17:43:33.146477Z",
     "shell.execute_reply.started": "2024-08-10T17:43:32.958608Z"
    }
   },
   "outputs": [],
   "source": [
    "datas_semi = []\n",
    "labels_semi = []\n",
    "scans_semi = []\n",
    "\n",
    "for i in incorrect_predictions3:\n",
    "        img_files = glob.glob(os.path.join(\"/kaggle/input/spie-cropped-resampled-dataset/Luna_16_cropped_resampled/Luna_16_cropped_resampled/\", i + \"*.nii\"))\n",
    "\n",
    "        for img_file in img_files:\n",
    "            img = nib.load(img_file)\n",
    "            data = img.get_fdata()\n",
    "            datas_semi.append(data)\n",
    "            scans_semi.append(i)\n",
    "\n",
    "X_semi4 = np.array(datas_semi)\n",
    "z_semi4 = np.array(scans_semi)\n",
    "\n",
    "print(X_semi4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T17:43:34.739885Z",
     "iopub.status.busy": "2024-08-10T17:43:34.739470Z",
     "iopub.status.idle": "2024-08-10T17:43:35.022948Z",
     "shell.execute_reply": "2024-08-10T17:43:35.021939Z",
     "shell.execute_reply.started": "2024-08-10T17:43:34.739849Z"
    }
   },
   "outputs": [],
   "source": [
    "correct_predictions4 = []\n",
    "incorrect_predictions4 = []\n",
    "\n",
    "predictions = best_model4.predict(X_semi4)\n",
    "for i in range(len(X_semi4)):\n",
    "    if predictions[i] > 0.9:\n",
    "        correct_predictions4.append((z_luna_semi[i], 1))\n",
    "    elif predictions[i] < 0.1:\n",
    "        correct_predictions4.append((z_luna_semi[i], 0))\n",
    "    else:\n",
    "        incorrect_predictions4.append(z_luna_semi[i])\n",
    "\n",
    "# Create a DataFrame with 'scan' and 'malignancy' columns\n",
    "df_correct_predictions4 = pd.DataFrame(correct_predictions4, columns=['scan', 'malignancy'])\n",
    "\n",
    "print(df_correct_predictions4.shape)\n",
    "print(len(incorrect_predictions4),len(correct_predictions4))\n",
    "\n",
    "scan_identifiers_z_train5 = np.array([item[0] for item in correct_predictions4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T17:43:39.841729Z",
     "iopub.status.busy": "2024-08-10T17:43:39.841321Z",
     "iopub.status.idle": "2024-08-10T17:43:41.769994Z",
     "shell.execute_reply": "2024-08-10T17:43:41.768976Z",
     "shell.execute_reply.started": "2024-08-10T17:43:39.841697Z"
    }
   },
   "outputs": [],
   "source": [
    "datas_train = []\n",
    "labels_train=[]\n",
    "scans_train=[]\n",
    "\n",
    "datas_val = []\n",
    "labels_val=[]\n",
    "scans_val=[]\n",
    "\n",
    "\n",
    "\n",
    "for i in scan_identifiers_z_train5:\n",
    "    lab = df_correct_predictions4.loc[df_correct_predictions4['scan'] == i, 'malignancy'].values[0]\n",
    "    img_files = glob.glob(os.path.join(\"/kaggle/input/spie-cropped-resampled-dataset/Luna_16_cropped_resampled/Luna_16_cropped_resampled/\", i + \"*.nii\"))\n",
    "\n",
    "    scans_train.append(i)\n",
    "    for img_file in img_files:\n",
    "        img = nib.load(img_file)\n",
    "        data = img.get_fdata()\n",
    "\n",
    "        for j in range(len(angles)):\n",
    "            rotated_nifti = aug_rotate(data)\n",
    "            datas_train.append(rotated_nifti.get_fdata())\n",
    "            labels_train.append(lab)\n",
    "\n",
    "\n",
    "\n",
    "X_train5=np.array(datas_train)\n",
    "y_train5=np.array(labels_train)\n",
    "z_train5=np.array(scans_train)\n",
    "\n",
    "print(z_train5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T17:43:41.771842Z",
     "iopub.status.busy": "2024-08-10T17:43:41.771556Z",
     "iopub.status.idle": "2024-08-10T17:43:42.480995Z",
     "shell.execute_reply": "2024-08-10T17:43:42.480054Z",
     "shell.execute_reply.started": "2024-08-10T17:43:41.771813Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train1, X_train2 , X_train3 , X_train4 , X_train5))\n",
    "y_train = np.concatenate((y_train1, y_train2 , y_train3 , y_train4 , y_train5))\n",
    "z_train = np.concatenate((z_train1, z_train2 , z_train3 , z_train4 , z_train5))\n",
    "print(z_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5th train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T17:43:43.000100Z",
     "iopub.status.busy": "2024-08-10T17:43:42.999160Z",
     "iopub.status.idle": "2024-08-10T17:54:37.341649Z",
     "shell.execute_reply": "2024-08-10T17:54:37.340475Z",
     "shell.execute_reply.started": "2024-08-10T17:43:43.000038Z"
    }
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model=define_model()\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.001,\n",
    "        patience=5,\n",
    "        min_lr=1e-6)\n",
    "\n",
    "# Define the model checkpoint callback to save the best model\n",
    "checkpoint_callback = ModelCheckpoint('semiSupervised_HU5.h5', monitor='val_accuracy',save_best_only=True)\n",
    "\n",
    "BATCH_SIZE_TPU = BS * strategy.num_replicas_in_sync\n",
    "# Fit data to model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val1, y_val1), epochs=E, batch_size=BATCH_SIZE_TPU,callbacks=[lr_callback,checkpoint_callback],verbose=0)\n",
    "\n",
    "\n",
    "# Evaluate the model - report accuracy and capture it into a list for future reporting\n",
    "best_model5 = tf.keras.models.load_model('semiSupervised_HU5.h5')\n",
    "\n",
    "loss5, accuracy5 = best_model5.evaluate(X_luna_fixed_test, y_luna_fixed_test)   \n",
    "\n",
    "print(f'Luna Accuracy: {accuracy5}')\n",
    "print('luna loss: ',loss5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T18:03:40.480105Z",
     "iopub.status.busy": "2024-08-10T18:03:40.478895Z",
     "iopub.status.idle": "2024-08-10T18:03:42.202912Z",
     "shell.execute_reply": "2024-08-10T18:03:42.202114Z",
     "shell.execute_reply.started": "2024-08-10T18:03:40.480044Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = best_model5.predict(X_luna_fixed_test)\n",
    "predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Generate the classification report\n",
    "class_names = list(['benign','malignant'])\n",
    "report5 = classification_report(y_luna_fixed_test, predicted_classes , target_names=class_names)\n",
    "print(\"Classification Report:\\n\", report5)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm5 = confusion_matrix(y_luna_fixed_test, predicted_classes )\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm5, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "auc = roc_auc_score(y_luna_fixed_test, predictions)\n",
    "print(f'AUC: {auc}')\n",
    "#---------------------------------------------------------\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T18:03:43.149685Z",
     "iopub.status.busy": "2024-08-10T18:03:43.149329Z",
     "iopub.status.idle": "2024-08-10T18:03:43.277176Z",
     "shell.execute_reply": "2024-08-10T18:03:43.276236Z",
     "shell.execute_reply.started": "2024-08-10T18:03:43.149654Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(X_train5,open('train5_x','wb'))\n",
    "pickle.dump(y_train5,open('train5_y','wb'))\n",
    "pickle.dump(z_train5,open('train5_z','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unpredicted data after fifth train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T18:03:45.497889Z",
     "iopub.status.busy": "2024-08-10T18:03:45.497561Z",
     "iopub.status.idle": "2024-08-10T18:03:45.550550Z",
     "shell.execute_reply": "2024-08-10T18:03:45.549656Z",
     "shell.execute_reply.started": "2024-08-10T18:03:45.497863Z"
    }
   },
   "outputs": [],
   "source": [
    "datas_semi = []\n",
    "labels_semi = []\n",
    "scans_semi = []\n",
    "\n",
    "for i in incorrect_predictions4:\n",
    "        img_files = glob.glob(os.path.join(\"/kaggle/input/spie-cropped-resampled-dataset/Luna_16_cropped_resampled/Luna_16_cropped_resampled/\", i + \"*.nii\"))\n",
    "\n",
    "        for img_file in img_files:\n",
    "            img = nib.load(img_file)\n",
    "            data = img.get_fdata()\n",
    "            datas_semi.append(data)\n",
    "            scans_semi.append(i)\n",
    "\n",
    "X_semi5 = np.array(datas_semi)\n",
    "z_semi5 = np.array(scans_semi)\n",
    "\n",
    "print(X_semi5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T18:03:47.821478Z",
     "iopub.status.busy": "2024-08-10T18:03:47.821154Z",
     "iopub.status.idle": "2024-08-10T18:03:48.003868Z",
     "shell.execute_reply": "2024-08-10T18:03:48.002915Z",
     "shell.execute_reply.started": "2024-08-10T18:03:47.821451Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = best_model5.predict(X_semi5)\n",
    "correct_predictions5 = []\n",
    "incorrect_predictions5 = []\n",
    "\n",
    "for i in range(len(X_semi5)):\n",
    "    if predictions[i] > 0.9:\n",
    "        correct_predictions5.append((z_luna_semi[i], 1))\n",
    "    elif predictions[i] < 0.1:\n",
    "        correct_predictions5.append((z_luna_semi[i], 0))\n",
    "    else:\n",
    "        incorrect_predictions5.append(z_luna_semi[i])\n",
    "\n",
    "# Create a DataFrame with 'scan' and 'malignancy' columns\n",
    "df_correct_predictions5 = pd.DataFrame(correct_predictions5, columns=['scan', 'malignancy'])\n",
    "\n",
    "print(len(incorrect_predictions5), len(correct_predictions5))\n",
    "\n",
    "scan_identifiers_z_train6 = np.array([item[0] for item in correct_predictions5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T18:03:51.375699Z",
     "iopub.status.busy": "2024-08-10T18:03:51.375382Z",
     "iopub.status.idle": "2024-08-10T18:03:51.648044Z",
     "shell.execute_reply": "2024-08-10T18:03:51.647272Z",
     "shell.execute_reply.started": "2024-08-10T18:03:51.375673Z"
    }
   },
   "outputs": [],
   "source": [
    "datas_train = []\n",
    "labels_train=[]\n",
    "scans_train=[]\n",
    "\n",
    "datas_val = []\n",
    "labels_val=[]\n",
    "scans_val=[]\n",
    "\n",
    "\n",
    "\n",
    "for i in scan_identifiers_z_train6:\n",
    "    lab = df_correct_predictions5.loc[df_correct_predictions5['scan'] == i, 'malignancy'].values[0]\n",
    "    img_files = glob.glob(os.path.join(\"/kaggle/input/spie-cropped-resampled-dataset/Luna_16_cropped_resampled/Luna_16_cropped_resampled/\", i + \"*.nii\"))\n",
    "\n",
    "    scans_train.append(i)\n",
    "    for img_file in img_files:\n",
    "        img = nib.load(img_file)\n",
    "        data = img.get_fdata()\n",
    "\n",
    "        for j in range(len(angles)):\n",
    "            rotated_nifti = aug_rotate(data)\n",
    "            datas_train.append(rotated_nifti.get_fdata())\n",
    "            labels_train.append(lab)\n",
    "\n",
    "\n",
    "\n",
    "X_train6=np.array(datas_train)\n",
    "y_train6=np.array(labels_train)\n",
    "z_train6=np.array(scans_train)\n",
    "\n",
    "print(z_train6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T18:03:53.265158Z",
     "iopub.status.busy": "2024-08-10T18:03:53.264817Z",
     "iopub.status.idle": "2024-08-10T18:03:53.990788Z",
     "shell.execute_reply": "2024-08-10T18:03:53.989863Z",
     "shell.execute_reply.started": "2024-08-10T18:03:53.265131Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train1, X_train2 , X_train3 , X_train4 , X_train5 , X_train6))\n",
    "y_train = np.concatenate((y_train1, y_train2 , y_train3 , y_train4 , y_train5 , y_train6))\n",
    "z_train = np.concatenate((z_train1, z_train2 , z_train3 , z_train4 , z_train5 , z_train6))\n",
    "print(z_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6th train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T18:03:55.319718Z",
     "iopub.status.busy": "2024-08-10T18:03:55.319389Z",
     "iopub.status.idle": "2024-08-10T18:15:42.599829Z",
     "shell.execute_reply": "2024-08-10T18:15:42.598706Z",
     "shell.execute_reply.started": "2024-08-10T18:03:55.319688Z"
    }
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model=define_model()\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.001,\n",
    "        patience=5,\n",
    "        min_lr=1e-6)\n",
    "\n",
    "# Define the model checkpoint callback to save the best model\n",
    "checkpoint_callback = ModelCheckpoint('semiSupervised_HU6.h5', monitor='val_accuracy',save_best_only=True)\n",
    "\n",
    "BATCH_SIZE_TPU = BS * strategy.num_replicas_in_sync\n",
    "# Fit data to model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val1, y_val1), epochs=E, batch_size=BATCH_SIZE_TPU,callbacks=[lr_callback,checkpoint_callback],verbose=0)\n",
    "\n",
    "\n",
    "# Evaluate the model - report accuracy and capture it into a list for future reporting\n",
    "best_model6 = tf.keras.models.load_model('semiSupervised_HU6.h5')\n",
    "\n",
    "loss6, accuracy6 = best_model6.evaluate(X_luna_fixed_test, y_luna_fixed_test)   \n",
    "print(f'Luna Accuracy: {accuracy6}')\n",
    "print('luna loss: ',loss6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T18:20:59.485776Z",
     "iopub.status.busy": "2024-08-10T18:20:59.485319Z",
     "iopub.status.idle": "2024-08-10T18:21:01.309051Z",
     "shell.execute_reply": "2024-08-10T18:21:01.308107Z",
     "shell.execute_reply.started": "2024-08-10T18:20:59.485742Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = best_model6.predict(X_luna_fixed_test)\n",
    "predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Generate the classification report\n",
    "class_names = list(['benign','malignant'])\n",
    "report6 = classification_report(y_luna_fixed_test, predicted_classes , target_names=class_names)\n",
    "print(\"Classification Report:\\n\", report6)\n",
    "\n",
    "auc = roc_auc_score(y_luna_fixed_test, predictions)\n",
    "print(f'AUC: {auc}')\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm6 = confusion_matrix(y_luna_fixed_test, predicted_classes )\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm6, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#---------------------------------------------------------\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T18:21:05.641638Z",
     "iopub.status.busy": "2024-08-10T18:21:05.640472Z",
     "iopub.status.idle": "2024-08-10T18:21:05.670249Z",
     "shell.execute_reply": "2024-08-10T18:21:05.669124Z",
     "shell.execute_reply.started": "2024-08-10T18:21:05.641597Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(X_train6,open('train5_x','wb'))\n",
    "pickle.dump(y_train6,open('train5_y','wb'))\n",
    "pickle.dump(z_train6,open('train5_z','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unpredicted data after sixth train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T18:21:09.441952Z",
     "iopub.status.busy": "2024-08-10T18:21:09.441175Z",
     "iopub.status.idle": "2024-08-10T18:21:09.484997Z",
     "shell.execute_reply": "2024-08-10T18:21:09.483937Z",
     "shell.execute_reply.started": "2024-08-10T18:21:09.441914Z"
    }
   },
   "outputs": [],
   "source": [
    "datas_semi = []\n",
    "labels_semi = []\n",
    "scans_semi = []\n",
    "\n",
    "for i in incorrect_predictions5:\n",
    "        img_files = glob.glob(os.path.join(\"/kaggle/input/spie-cropped-resampled-dataset/Luna_16_cropped_resampled/Luna_16_cropped_resampled/\", i + \"*.nii\"))\n",
    "\n",
    "        for img_file in img_files:\n",
    "            img = nib.load(img_file)\n",
    "            data = img.get_fdata()\n",
    "            datas_semi.append(data)\n",
    "            scans_semi.append(i)\n",
    "\n",
    "X_semi6 = np.array(datas_semi)\n",
    "z_semi6 = np.array(scans_semi)\n",
    "\n",
    "print(X_semi6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T18:21:12.998769Z",
     "iopub.status.busy": "2024-08-10T18:21:12.997692Z",
     "iopub.status.idle": "2024-08-10T18:21:13.130536Z",
     "shell.execute_reply": "2024-08-10T18:21:13.129251Z",
     "shell.execute_reply.started": "2024-08-10T18:21:12.998729Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = best_model6.predict(X_semi6)\n",
    "correct_predictions6 = []\n",
    "incorrect_predictions6 = []\n",
    "\n",
    "for i in range(len(X_semi6)):\n",
    "    if predictions[i] > 0.9:\n",
    "        correct_predictions6.append((z_luna_semi[i], 1))\n",
    "    elif predictions[i] < 0.1:\n",
    "        correct_predictions6.append((z_luna_semi[i], 0))\n",
    "    else:\n",
    "        incorrect_predictions6.append(z_luna_semi[i])\n",
    "\n",
    "# Create a DataFrame with 'scan' and 'malignancy' columns\n",
    "df_correct_predictions6 = pd.DataFrame(correct_predictions6, columns=['scan', 'malignancy'])\n",
    "\n",
    "print(len(incorrect_predictions6), len(correct_predictions6))\n",
    "\n",
    "scan_identifiers_z_train7 = np.array([item[0] for item in correct_predictions6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T18:22:29.759137Z",
     "iopub.status.busy": "2024-08-10T18:22:29.758137Z",
     "iopub.status.idle": "2024-08-10T18:22:29.841876Z",
     "shell.execute_reply": "2024-08-10T18:22:29.840786Z",
     "shell.execute_reply.started": "2024-08-10T18:22:29.759096Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming z_train1, z_train2, etc., are numpy arrays\n",
    "z_train_lists = [z_train1, z_train2, z_train3, z_train4, z_train5, z_train6]\n",
    "z_val_lists = [z_val1]\n",
    "\n",
    "# Create DataFrames from numpy arrays with unique column names\n",
    "df_train_list = [pd.DataFrame({f'z_train{i + 1}': z_train}) for i, z_train in enumerate(z_train_lists)]\n",
    "df_val_list = [pd.DataFrame({'z_val': z_val}) for z_val in z_val_lists]\n",
    "\n",
    "# Concatenate the DataFrames along the columns\n",
    "df_combined = pd.concat(df_val_list + df_train_list, axis=1)\n",
    "\n",
    "# Save the combined DataFrame to an Excel file\n",
    "df_combined.to_excel('combined_train_val_lists.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T18:22:41.680328Z",
     "iopub.status.busy": "2024-08-10T18:22:41.679310Z",
     "iopub.status.idle": "2024-08-10T18:22:41.726650Z",
     "shell.execute_reply": "2024-08-10T18:22:41.725703Z",
     "shell.execute_reply.started": "2024-08-10T18:22:41.680292Z"
    }
   },
   "outputs": [],
   "source": [
    "all_dfs = [df_correct_predictions1, df_correct_predictions2,df_correct_predictions3,df_correct_predictions4,df_correct_predictions5]\n",
    "result_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# Save the concatenated DataFrame to an Excel file\n",
    "result_df.to_excel('output_file.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T18:22:43.697733Z",
     "iopub.status.busy": "2024-08-10T18:22:43.696573Z",
     "iopub.status.idle": "2024-08-10T18:22:43.708475Z",
     "shell.execute_reply": "2024-08-10T18:22:43.707553Z",
     "shell.execute_reply.started": "2024-08-10T18:22:43.697673Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_list = [round(accuracy * 100, 2) for accuracy in [accuracy1, accuracy2,accuracy3, accuracy4, accuracy5, accuracy6]]\n",
    "loss_list = [round(loss * 100, 2) for loss in [loss1, loss2,loss3, loss4, loss5, loss6]]\n",
    "\n",
    "df_accloss = pd.DataFrame({ 'accuracy': accuracy_list, 'loss': loss_list})\n",
    "print(df_accloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T18:23:36.233992Z",
     "iopub.status.busy": "2024-08-10T18:23:36.233616Z",
     "iopub.status.idle": "2024-08-10T18:23:41.201992Z",
     "shell.execute_reply": "2024-08-10T18:23:41.201116Z",
     "shell.execute_reply.started": "2024-08-10T18:23:36.233960Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train1, X_train2 , X_train3 , X_train4 , X_train5,X_train6))\n",
    "y_train = np.concatenate((y_train1, y_train2 , y_train3 , y_train4 , y_train5,y_train6))\n",
    "z_train = np.concatenate((z_train1, z_train2 , z_train3 , z_train4 , z_train5,z_train6))\n",
    "print(z_train.shape)\n",
    "\n",
    "X_test= X_luna_fixed_test\n",
    "y_test= y_luna_fixed_test\n",
    "z_test= z_luna_fixed_test\n",
    "\n",
    "pickle.dump(X_train,open('train_x','wb'))\n",
    "pickle.dump(y_train,open('train_y','wb'))\n",
    "pickle.dump(z_train,open('train_z','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing into 2 branches random initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T18:24:21.760568Z",
     "iopub.status.busy": "2024-08-10T18:24:21.760223Z",
     "iopub.status.idle": "2024-08-10T18:24:21.780159Z",
     "shell.execute_reply": "2024-08-10T18:24:21.779264Z",
     "shell.execute_reply.started": "2024-08-10T18:24:21.760541Z"
    }
   },
   "outputs": [],
   "source": [
    "# Custom layer with trainable variables\n",
    "from tensorflow.keras.constraints import Constraint\n",
    "\n",
    "class RangeConstraint(Constraint):\n",
    "    def __init__(self, min_value=0.0, max_value=1.0):\n",
    "        self.min_value = min_value\n",
    "        self.max_value = max_value\n",
    "\n",
    "    def __call__(self, w):\n",
    "        return tf.clip_by_value(w, self.min_value, self.max_value)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'min_value': self.min_value, 'max_value': self.max_value}\n",
    "\n",
    "\n",
    "# Custom layer with trainable variables\n",
    "class LearnableDynamicRange(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        # Use the provided name or the default name if not provided\n",
    "        name = kwargs.pop('name', 'learnable_dynamic_range')\n",
    "        super(LearnableDynamicRange, self).__init__(name=name, **kwargs)\n",
    "\n",
    "        # Define trainable variables with initial values\n",
    "        self.a = self.add_weight(\n",
    "            name='a',\n",
    "            shape=(1,),\n",
    "            initializer=tf.random_uniform_initializer(minval=0.0, maxval=1.0),\n",
    "            constraint=RangeConstraint(min_value=0.3, max_value=0.7),\n",
    "            trainable=True\n",
    "        )\n",
    "      \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        a_layer = tf.where(inputs > self.a, 1.0, inputs / self.a)\n",
    "        b_layer = tf.clip_by_value((inputs - self.a) / (1 - self.a), 0, 1)\n",
    "\n",
    "\n",
    "        return a_layer, b_layer\n",
    "\n",
    "\n",
    "# Model\n",
    "def conv_block(inputs):\n",
    "    x = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPool3D((2, 2, 2))(x)\n",
    "    \n",
    "    x = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPool3D((2, 2, 2))(x)\n",
    "    \n",
    "    x = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPool3D((2, 2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPool3D((2, 2, 2))(x)\n",
    "    \n",
    "    x = Conv3D(256, (3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv3D(256, (3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPool3D((2, 2, 2))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def define_model():\n",
    "    input_shape = (32, 32, 32, 1)\n",
    "    input_data = Input(shape=input_shape)\n",
    "\n",
    "    # Use the custom layer with trainable variables\n",
    "    dynamic_range_layer = LearnableDynamicRange()(input_data)\n",
    "    a_layer, b_layer= dynamic_range_layer\n",
    "\n",
    "    branch_a = conv_block(a_layer)\n",
    "    branch_b = conv_block(b_layer)\n",
    "    \n",
    "    concatenated_branches = concatenate([branch_a, branch_b])\n",
    "\n",
    "    x = Dense(128, activation='relu', kernel_initializer='he_uniform')(concatenated_branches)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(64, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(32, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(8, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "\n",
    "    output_layer = Dense(1, activation='sigmoid', kernel_initializer='he_uniform')(x)\n",
    "\n",
    "    model = Model(inputs=input_data, outputs=output_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T18:24:33.982114Z",
     "iopub.status.busy": "2024-08-10T18:24:33.981707Z",
     "iopub.status.idle": "2024-08-10T18:43:56.500502Z",
     "shell.execute_reply": "2024-08-10T18:43:56.499337Z",
     "shell.execute_reply.started": "2024-08-10T18:24:33.982066Z"
    }
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model=define_model()\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.001,\n",
    "        patience=5,\n",
    "        min_lr=1e-6)\n",
    "checkpoint_callback = ModelCheckpoint('Luna_train1.h5', monitor='val_accuracy',save_best_only=True, save_format='tf')\n",
    "\n",
    "\n",
    "BATCH_SIZE_TPU = BS * strategy.num_replicas_in_sync\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val1, y_val1), epochs=E, batch_size=BATCH_SIZE_TPU,callbacks=[checkpoint_callback,lr_callback],verbose=0)\n",
    "\n",
    "\n",
    "best_model1 = tf.keras.models.load_model('Luna_train1.h5', custom_objects={'LearnableDynamicRange': LearnableDynamicRange})\n",
    "\n",
    "loss1, accuracy1 = best_model1.evaluate(X_test, y_test)\n",
    "print('accuracy: ',accuracy1*100)\n",
    "print('loss: ',loss1*100)\n",
    "\n",
    "print('-----------------------------------------------------------------')\n",
    "a_value = best_model1.get_layer('learnable_dynamic_range').a.numpy()\n",
    "print(\"Value of 'a' in the best model:\", a_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T18:54:05.312619Z",
     "iopub.status.busy": "2024-08-10T18:54:05.312248Z",
     "iopub.status.idle": "2024-08-10T18:54:08.029861Z",
     "shell.execute_reply": "2024-08-10T18:54:08.028915Z",
     "shell.execute_reply.started": "2024-08-10T18:54:05.312591Z"
    }
   },
   "outputs": [],
   "source": [
    "auc_df = pd.DataFrame(columns=['AUC'])   \n",
    "\n",
    "\n",
    "luna_correct_hu1=[]\n",
    "predictions1 = best_model1.predict(X_test)\n",
    "predicted_classes = (predictions1 > 0.5).astype(int)\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "# Generate the classification report\n",
    "class_names = list(['benign','malignant'])\n",
    "report = classification_report(y_test, predicted_classes, target_names=class_names,digits=5)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Calculate AUC\n",
    "auc = roc_auc_score(y_test, predictions1)\n",
    "print(f'AUC: {auc}')\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, predicted_classes )\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# Extract micro avg \n",
    "report0 = classification_report(y_test, predicted_classes, target_names=class_names,digits=5,output_dict=True)\n",
    "precision = report0['macro avg']['precision']\n",
    "recall = report0['macro avg']['recall']\n",
    "f1_score = report0['macro avg']['f1-score']\n",
    "combined_row = {'AUC': auc*100, 'Precision': precision*100, 'Recall': recall*100, 'F1-Score': f1_score*100}\n",
    "combined_row_df = pd.DataFrame([combined_row])\n",
    "auc_df = pd.concat([auc_df, combined_row_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing into 2 branches constant initializer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T18:54:13.912969Z",
     "iopub.status.busy": "2024-08-10T18:54:13.912592Z",
     "iopub.status.idle": "2024-08-10T18:54:13.927210Z",
     "shell.execute_reply": "2024-08-10T18:54:13.925788Z",
     "shell.execute_reply.started": "2024-08-10T18:54:13.912937Z"
    }
   },
   "outputs": [],
   "source": [
    "# Custom layer with trainable variables\n",
    "class LearnableDynamicRange(Layer):\n",
    "    def __init__(self, initial_a, **kwargs):\n",
    "        # Use the provided name or the default name if not provided\n",
    "        name = kwargs.pop('name', 'learnable_dynamic_range')\n",
    "        super(LearnableDynamicRange, self).__init__(name=name, **kwargs)\n",
    "\n",
    "        # Define trainable variables with initial values\n",
    "        self.a = self.add_weight(\n",
    "            name='a',\n",
    "            shape=(1,),\n",
    "            initializer=tf.constant_initializer(value=initial_a),\n",
    "            trainable=True\n",
    "        )\n",
    "       \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        a_layer = tf.where(inputs > self.a, 1.0, inputs / self.a)\n",
    "        b_layer = tf.clip_by_value((inputs - self.a) / (1 - self.a), 0, 1)\n",
    "\n",
    "\n",
    "        return a_layer, b_layer\n",
    "\n",
    "\n",
    "def define_model(initial_a):\n",
    "    input_shape = (32, 32, 32, 1)\n",
    "    input_data = Input(shape=input_shape)\n",
    "\n",
    "    # Use the custom layer with trainable variables\n",
    "    dynamic_range_layer = LearnableDynamicRange(initial_a=initial_a)(input_data)\n",
    "    a_layer, b_layer = dynamic_range_layer\n",
    "\n",
    "    branch_a = conv_block(a_layer)\n",
    "    branch_b = conv_block(b_layer)\n",
    "    \n",
    "\n",
    "    concatenated_branches = concatenate([branch_a, branch_b])\n",
    "\n",
    "    x = Dense(128, activation='relu', kernel_initializer='he_uniform')(concatenated_branches)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(64, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(32, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(8, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "\n",
    "    output_layer = Dense(1, activation='sigmoid', kernel_initializer='he_uniform')(x)\n",
    "\n",
    "    model = Model(inputs=input_data, outputs=output_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T18:54:16.940582Z",
     "iopub.status.busy": "2024-08-10T18:54:16.939465Z",
     "iopub.status.idle": "2024-08-10T19:13:34.233654Z",
     "shell.execute_reply": "2024-08-10T19:13:34.232654Z",
     "shell.execute_reply.started": "2024-08-10T18:54:16.940522Z"
    }
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model=define_model(0.5)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.001,\n",
    "        patience=5,\n",
    "        min_lr=1e-6)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint('Luna_train2.h5', monitor='val_accuracy',save_best_only=True, save_format='tf')\n",
    "\n",
    "BATCH_SIZE_TPU = BS * strategy.num_replicas_in_sync\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val1, y_val1), epochs=E, batch_size=BATCH_SIZE_TPU,callbacks=[checkpoint_callback,lr_callback],verbose=0)\n",
    "    \n",
    "\n",
    "best_model2 = tf.keras.models.load_model('Luna_train2.h5', custom_objects={'LearnableDynamicRange': LearnableDynamicRange})\n",
    "\n",
    "loss2, accuracy2 = best_model2.evaluate(X_test, y_test)\n",
    "print('accuracy: ',accuracy2*100)\n",
    "print('loss: ',loss2*100)\n",
    "\n",
    "print('-----------------------------------------------------------------')\n",
    "a_value = best_model2.get_layer('learnable_dynamic_range').a.numpy()\n",
    "print(\"Value of 'a' in the best model:\", a_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T19:21:28.685017Z",
     "iopub.status.busy": "2024-08-10T19:21:28.684611Z",
     "iopub.status.idle": "2024-08-10T19:21:31.567781Z",
     "shell.execute_reply": "2024-08-10T19:21:31.566913Z",
     "shell.execute_reply.started": "2024-08-10T19:21:28.684985Z"
    }
   },
   "outputs": [],
   "source": [
    "luna_correct_hu2=[]\n",
    "predictions2 = best_model2.predict(X_test)\n",
    "predicted_classes = (predictions2 > 0.5).astype(int)\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "# Generate the classification report\n",
    "class_names = list(['benign','malignant'])\n",
    "report = classification_report(y_test, predicted_classes, target_names=class_names,digits=5)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Calculate AUC\n",
    "auc = roc_auc_score(y_test, predictions2)\n",
    "print(f'AUC: {auc}')\n",
    "\n",
    "\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, predicted_classes )\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# Extract micro avg \n",
    "report0 = classification_report(y_test, predicted_classes, target_names=class_names,digits=5,output_dict=True)\n",
    "precision = report0['macro avg']['precision']\n",
    "recall = report0['macro avg']['recall']\n",
    "f1_score = report0['macro avg']['f1-score']\n",
    "combined_row = {'AUC': auc*100, 'Precision': precision*100, 'Recall': recall*100, 'F1-Score': f1_score*100}\n",
    "combined_row_df = pd.DataFrame([combined_row])\n",
    "auc_df = pd.concat([auc_df, combined_row_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing into 3 branches constant initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T19:23:16.501678Z",
     "iopub.status.busy": "2024-08-10T19:23:16.501009Z",
     "iopub.status.idle": "2024-08-10T19:23:16.527157Z",
     "shell.execute_reply": "2024-08-10T19:23:16.526316Z",
     "shell.execute_reply.started": "2024-08-10T19:23:16.501608Z"
    }
   },
   "outputs": [],
   "source": [
    "# Custom layer with trainable variables\n",
    "class LearnableDynamicRange(Layer):\n",
    "    def __init__(self, initial_a, initial_b, **kwargs):\n",
    "        # Use the provided name or the default name if not provided\n",
    "        name = kwargs.pop('name', 'learnable_dynamic_range')\n",
    "        super(LearnableDynamicRange, self).__init__(name=name, **kwargs)\n",
    "\n",
    "        # Define trainable variables with initial values\n",
    "        self.a = self.add_weight(\n",
    "            name='a',\n",
    "            shape=(1,),\n",
    "            initializer=tf.constant_initializer(value=initial_a),\n",
    "            trainable=True\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            name='b',\n",
    "            shape=(1,),\n",
    "            initializer=tf.constant_initializer(value=initial_b),\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        a_layer = tf.where(inputs > self.a, 1.0, inputs / self.a)\n",
    "        b_layer = tf.clip_by_value(tf.where(inputs > self.b, 1.0, (inputs - self.a) / (self.b - self.a)), 0, 1)\n",
    "        c_layer = tf.clip_by_value((inputs - self.b) / (1 - self.b), 0, 1)\n",
    "\n",
    "\n",
    "        return a_layer, b_layer, c_layer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def define_model(initial_a, initial_b):\n",
    "    input_shape = (32, 32, 32, 1)\n",
    "    input_data = Input(shape=input_shape)\n",
    "\n",
    "    # Use the custom layer with trainable variables\n",
    "    dynamic_range_layer = LearnableDynamicRange(initial_a=initial_a, initial_b=initial_b)(input_data)\n",
    "    a_layer, b_layer, c_layer = dynamic_range_layer\n",
    "\n",
    "    branch_a = conv_block(a_layer)\n",
    "    branch_b = conv_block(b_layer)\n",
    "    branch_c = conv_block(c_layer)\n",
    "\n",
    "    \n",
    "\n",
    "    concatenated_branches = concatenate([branch_a, branch_b, branch_c])\n",
    "\n",
    "    x = Dense(128, activation='relu', kernel_initializer='he_uniform')(concatenated_branches)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(64, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(32, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(8, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "\n",
    "    output_layer = Dense(1, activation='sigmoid', kernel_initializer='he_uniform')(x)\n",
    "\n",
    "    model = Model(inputs=input_data, outputs=output_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T19:23:19.892139Z",
     "iopub.status.busy": "2024-08-10T19:23:19.891725Z",
     "iopub.status.idle": "2024-08-10T19:49:29.649705Z",
     "shell.execute_reply": "2024-08-10T19:49:29.648552Z",
     "shell.execute_reply.started": "2024-08-10T19:23:19.892080Z"
    }
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model=define_model(0.33,0.66)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.001,\n",
    "        patience=5,\n",
    "        min_lr=1e-6)\n",
    "checkpoint_callback = ModelCheckpoint('Luna_train4.h5', monitor='val_accuracy',save_best_only=True, save_format='tf')\n",
    "\n",
    "BATCH_SIZE_TPU = BS * strategy.num_replicas_in_sync\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val1, y_val1), epochs=E, batch_size=BATCH_SIZE_TPU,callbacks=[checkpoint_callback,lr_callback],verbose=0)\n",
    "    \n",
    "\n",
    "best_model4 = tf.keras.models.load_model('Luna_train4.h5', custom_objects={'LearnableDynamicRange': LearnableDynamicRange})\n",
    "\n",
    "loss4, accuracy4 = best_model4.evaluate(X_test, y_test)\n",
    "print('accuracy: ',accuracy4*100)\n",
    "print('loss: ',loss4*100)\n",
    "\n",
    "print('--------------------------------------------------------------------')\n",
    "a_value = best_model4.get_layer('learnable_dynamic_range').a.numpy()\n",
    "b_value = best_model4.get_layer('learnable_dynamic_range').b.numpy()\n",
    "print(\"Value of 'a' in the best model:\", a_value)\n",
    "print(\"Value of 'b' in the best model:\", b_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T19:49:29.651647Z",
     "iopub.status.busy": "2024-08-10T19:49:29.651337Z",
     "iopub.status.idle": "2024-08-10T19:49:33.139074Z",
     "shell.execute_reply": "2024-08-10T19:49:33.138071Z",
     "shell.execute_reply.started": "2024-08-10T19:49:29.651615Z"
    }
   },
   "outputs": [],
   "source": [
    "luna_correct_hu4=[]\n",
    "predictions4 = best_model4.predict(X_test)\n",
    "predicted_classes = (predictions4 > 0.5).astype(int)\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "# Generate the classification report\n",
    "class_names = list(['benign','malignant'])\n",
    "report = classification_report(y_test, predicted_classes, target_names=class_names,digits=5)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Calculate AUC\n",
    "auc = roc_auc_score(y_test, predictions4)\n",
    "print(f'AUC: {auc}')\n",
    "\n",
    "\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, predicted_classes )\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# Extract micro avg \n",
    "report0 = classification_report(y_test, predicted_classes, target_names=class_names,digits=5,output_dict=True)\n",
    "precision = report0['macro avg']['precision']\n",
    "recall = report0['macro avg']['recall']\n",
    "f1_score = report0['macro avg']['f1-score']\n",
    "combined_row = {'AUC': auc*100, 'Precision': precision*100, 'Recall': recall*100, 'F1-Score': f1_score*100}\n",
    "combined_row_df = pd.DataFrame([combined_row])\n",
    "auc_df = pd.concat([auc_df, combined_row_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HU (with original input)\n",
    "## Dividing into 2 branches constant initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T19:51:12.290862Z",
     "iopub.status.busy": "2024-08-10T19:51:12.289816Z",
     "iopub.status.idle": "2024-08-10T19:51:12.301262Z",
     "shell.execute_reply": "2024-08-10T19:51:12.300318Z",
     "shell.execute_reply.started": "2024-08-10T19:51:12.290821Z"
    }
   },
   "outputs": [],
   "source": [
    "# Custom layer with trainable variables\n",
    "class LearnableDynamicRange(Layer):\n",
    "    def __init__(self, initial_a, **kwargs):\n",
    "        # Use the provided name or the default name if not provided\n",
    "        name = kwargs.pop('name', 'learnable_dynamic_range')\n",
    "        super(LearnableDynamicRange, self).__init__(name=name, **kwargs)\n",
    "\n",
    "        # Define trainable variables with initial values\n",
    "        self.a = self.add_weight(\n",
    "            name='a',\n",
    "            shape=(1,),\n",
    "            initializer=tf.constant_initializer(value=initial_a),\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        a_layer = tf.where(inputs > self.a, 1.0, inputs / self.a)\n",
    "        b_layer = tf.clip_by_value((inputs - self.a) / (1 - self.a), 0, 1)\n",
    "        c_layer = inputs\n",
    "\n",
    "        return a_layer, b_layer, c_layer\n",
    "\n",
    "\n",
    "\n",
    "def define_model(initial_a):\n",
    "    input_shape = (32, 32, 32, 1)\n",
    "    input_data = Input(shape=input_shape)\n",
    "\n",
    "    # Use the custom layer with trainable variables\n",
    "    dynamic_range_layer = LearnableDynamicRange(initial_a=initial_a)(input_data)\n",
    "    a_layer, b_layer, c_layer = dynamic_range_layer\n",
    "\n",
    "    branch_a = conv_block(a_layer)\n",
    "    branch_b = conv_block(b_layer)\n",
    "    branch_c = conv_block(c_layer)\n",
    "    \n",
    "\n",
    "    concatenated_branches = concatenate([branch_a, branch_b, branch_c])\n",
    "\n",
    "    x = Dense(128, activation='relu', kernel_initializer='he_uniform')(concatenated_branches)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(64, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(32, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(8, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "\n",
    "    output_layer = Dense(1, activation='sigmoid', kernel_initializer='he_uniform')(x)\n",
    "\n",
    "    model = Model(inputs=input_data, outputs=output_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T19:51:18.047134Z",
     "iopub.status.busy": "2024-08-10T19:51:18.046665Z",
     "iopub.status.idle": "2024-08-10T20:16:48.493217Z",
     "shell.execute_reply": "2024-08-10T20:16:48.491935Z",
     "shell.execute_reply.started": "2024-08-10T19:51:18.047088Z"
    }
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model=define_model(0.5)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.001,\n",
    "        patience=5,\n",
    "        min_lr=1e-6)\n",
    "checkpoint_callback = ModelCheckpoint('Luna_train14.h5', monitor='val_accuracy',save_best_only=True, save_format='tf')\n",
    "\n",
    "BATCH_SIZE_TPU = BS * strategy.num_replicas_in_sync\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val1, y_val1), epochs=E, batch_size=BATCH_SIZE_TPU,callbacks=[checkpoint_callback,lr_callback],verbose=0)\n",
    "    \n",
    "\n",
    "best_model14 = tf.keras.models.load_model('Luna_train14.h5', custom_objects={'LearnableDynamicRange': LearnableDynamicRange})\n",
    "\n",
    "loss14, accuracy14 = best_model14.evaluate(X_test, y_test)\n",
    "print('accuracy: ',accuracy14*100)\n",
    "print('loss: ',loss14*100)\n",
    "\n",
    "print('------------------------------------------------')\n",
    "a_value = best_model14.get_layer('learnable_dynamic_range').a.numpy()\n",
    "print(\"Value of 'a' in the best model:\", a_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T20:16:48.496057Z",
     "iopub.status.busy": "2024-08-10T20:16:48.495342Z",
     "iopub.status.idle": "2024-08-10T20:16:54.800823Z",
     "shell.execute_reply": "2024-08-10T20:16:54.799713Z",
     "shell.execute_reply.started": "2024-08-10T20:16:48.496017Z"
    }
   },
   "outputs": [],
   "source": [
    "luna_correct_hu14=[]\n",
    "predictions14 = best_model14.predict(X_test)\n",
    "predicted_classes = (predictions14 > 0.5).astype(int)\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "# Generate the classification report\n",
    "class_names = list(['benign','malignant'])\n",
    "report = classification_report(y_test, predicted_classes, target_names=class_names,digits=5)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Calculate AUC\n",
    "auc = roc_auc_score(y_test, predictions14)\n",
    "print(f'AUC: {auc}')\n",
    "\n",
    "\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, predicted_classes )\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# Extract micro avg \n",
    "report0 = classification_report(y_test, predicted_classes, target_names=class_names,digits=5,output_dict=True)\n",
    "precision = report0['macro avg']['precision']\n",
    "recall = report0['macro avg']['recall']\n",
    "f1_score = report0['macro avg']['f1-score']\n",
    "combined_row = {'AUC': auc*100, 'Precision': precision*100, 'Recall': recall*100, 'F1-Score': f1_score*100}\n",
    "combined_row_df = pd.DataFrame([combined_row])\n",
    "auc_df = pd.concat([auc_df, combined_row_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing into 3 branches constant initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T20:16:54.802645Z",
     "iopub.status.busy": "2024-08-10T20:16:54.802342Z",
     "iopub.status.idle": "2024-08-10T20:16:54.814926Z",
     "shell.execute_reply": "2024-08-10T20:16:54.814078Z",
     "shell.execute_reply.started": "2024-08-10T20:16:54.802598Z"
    }
   },
   "outputs": [],
   "source": [
    "# Custom layer with trainable variables\n",
    "class LearnableDynamicRange(Layer):\n",
    "    def __init__(self, initial_a, initial_b, **kwargs):\n",
    "        # Use the provided name or the default name if not provided\n",
    "        name = kwargs.pop('name', 'learnable_dynamic_range')\n",
    "        super(LearnableDynamicRange, self).__init__(name=name, **kwargs)\n",
    "\n",
    "        # Define trainable variables with initial values\n",
    "        self.a = self.add_weight(\n",
    "            name='a',\n",
    "            shape=(1,),\n",
    "            initializer=tf.constant_initializer(value=initial_a),\n",
    "            trainable=True\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            name='b',\n",
    "            shape=(1,),\n",
    "            initializer=tf.constant_initializer(value=initial_b),\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        a_layer = tf.where(inputs > self.a, 1.0, inputs / self.a)\n",
    "        b_layer = tf.clip_by_value(tf.where(inputs > self.b, 1.0, (inputs - self.a) / (self.b - self.a)), 0, 1)\n",
    "        c_layer = tf.clip_by_value((inputs - self.b) / (1 - self.b), 0, 1)\n",
    "        d_layer = inputs\n",
    "\n",
    "        return a_layer, b_layer, c_layer, d_layer\n",
    "\n",
    "\n",
    "\n",
    "def define_model(initial_a, initial_b):\n",
    "    input_shape = (32, 32, 32, 1)\n",
    "    input_data = Input(shape=input_shape)\n",
    "\n",
    "    # Use the custom layer with trainable variables\n",
    "    dynamic_range_layer = LearnableDynamicRange(initial_a=initial_a, initial_b=initial_b)(input_data)\n",
    "    a_layer, b_layer, c_layer, d_layer = dynamic_range_layer\n",
    "\n",
    "    branch_a = conv_block(a_layer)\n",
    "    branch_b = conv_block(b_layer)\n",
    "    branch_c = conv_block(c_layer)\n",
    "    branch_d = conv_block(d_layer)\n",
    "    \n",
    "\n",
    "    concatenated_branches = concatenate([branch_a, branch_b, branch_c,branch_d])\n",
    "\n",
    "    x = Dense(128, activation='relu', kernel_initializer='he_uniform')(concatenated_branches)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(64, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(32, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(8, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "\n",
    "    output_layer = Dense(1, activation='sigmoid', kernel_initializer='he_uniform')(x)\n",
    "\n",
    "    model = Model(inputs=input_data, outputs=output_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T20:16:54.817195Z",
     "iopub.status.busy": "2024-08-10T20:16:54.816908Z",
     "iopub.status.idle": "2024-08-10T20:49:05.227160Z",
     "shell.execute_reply": "2024-08-10T20:49:05.225905Z",
     "shell.execute_reply.started": "2024-08-10T20:16:54.817168Z"
    }
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model=define_model(0.33,0.66)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.001,\n",
    "        patience=5,\n",
    "        min_lr=1e-6)\n",
    "checkpoint_callback = ModelCheckpoint('Luna_train16.h5', monitor='val_accuracy',save_best_only=True, save_format='tf')\n",
    "\n",
    "BATCH_SIZE_TPU = BS * strategy.num_replicas_in_sync\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val1, y_val1), epochs=E, batch_size=BATCH_SIZE_TPU,callbacks=[checkpoint_callback,lr_callback],verbose=0)\n",
    "    \n",
    "\n",
    "best_model16 = tf.keras.models.load_model('Luna_train16.h5', custom_objects={'LearnableDynamicRange': LearnableDynamicRange})\n",
    "\n",
    "loss16, accuracy16 = best_model16.evaluate(X_test, y_test)\n",
    "print('accuracy: ',accuracy16*100)\n",
    "print('loss: ',loss16*100)\n",
    "\n",
    "\n",
    "print('-----------------------------------------------------------------')\n",
    "a_value = best_model16.get_layer('learnable_dynamic_range').a.numpy()\n",
    "b_value = best_model16.get_layer('learnable_dynamic_range').b.numpy()\n",
    " \n",
    "print(\"Value of 'a' in the best model:\", a_value)\n",
    "print(\"Value of 'b' in the best model:\", b_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T20:49:05.228872Z",
     "iopub.status.busy": "2024-08-10T20:49:05.228548Z",
     "iopub.status.idle": "2024-08-10T20:49:09.577305Z",
     "shell.execute_reply": "2024-08-10T20:49:09.576383Z",
     "shell.execute_reply.started": "2024-08-10T20:49:05.228840Z"
    }
   },
   "outputs": [],
   "source": [
    "luna_correct_hu16=[]\n",
    "predictions16 = best_model16.predict(X_test)\n",
    "predicted_classes = (predictions16 > 0.5).astype(int)\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "# Generate the classification report\n",
    "class_names = list(['benign','malignant'])\n",
    "report = classification_report(y_test, predicted_classes, target_names=class_names,digits=5)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Calculate AUC\n",
    "auc = roc_auc_score(y_test, predictions16)\n",
    "print(f'AUC: {auc}')\n",
    "\n",
    "\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, predicted_classes )\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# Extract micro avg \n",
    "report0 = classification_report(y_test, predicted_classes, target_names=class_names,digits=5,output_dict=True)\n",
    "precision = report0['macro avg']['precision']\n",
    "recall = report0['macro avg']['recall']\n",
    "f1_score = report0['macro avg']['f1-score']\n",
    "combined_row = {'AUC': auc*100, 'Precision': precision*100, 'Recall': recall*100, 'F1-Score': f1_score*100}\n",
    "combined_row_df = pd.DataFrame([combined_row])\n",
    "auc_df = pd.concat([auc_df, combined_row_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T20:49:09.579074Z",
     "iopub.status.busy": "2024-08-10T20:49:09.578772Z",
     "iopub.status.idle": "2024-08-10T20:49:09.607649Z",
     "shell.execute_reply": "2024-08-10T20:49:09.606883Z",
     "shell.execute_reply.started": "2024-08-10T20:49:09.579032Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_list = [round(accuracy * 100, 2) for accuracy in [accuracy1, accuracy2, accuracy4, accuracy14, accuracy16]]\n",
    "\n",
    "col_head = [\n",
    "    '2 ranges (without original input, random)', \n",
    "    '2 ranges (without original input, constant)', \n",
    "    '3 ranges (without original input, constant)',\n",
    "    '2 ranges (+ original input, constant)',\n",
    "    '3 ranges (+ original input, constant)'\n",
    "]\n",
    "\n",
    "df_acc = pd.DataFrame({'type': col_head, 'accuracy': accuracy_list})\n",
    "print(df_acc)\n",
    "print(auc_df)\n",
    "# Save Excel file\n",
    "df_acc.to_excel('df_acc.xlsx', index=False)\n",
    "auc_df.to_excel('df_auc.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "datasetId": 3974254,
     "sourceId": 7321302,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30628,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
