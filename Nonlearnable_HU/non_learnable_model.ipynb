{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T07:36:18.037290Z",
     "iopub.status.busy": "2024-08-21T07:36:18.037037Z",
     "iopub.status.idle": "2024-08-21T07:36:30.183690Z",
     "shell.execute_reply": "2024-08-21T07:36:30.182792Z",
     "shell.execute_reply.started": "2024-08-21T07:36:18.037263Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install nibabel\n",
    "!pip install seaborn\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T07:36:30.185901Z",
     "iopub.status.busy": "2024-08-21T07:36:30.185351Z",
     "iopub.status.idle": "2024-08-21T07:36:44.734050Z",
     "shell.execute_reply": "2024-08-21T07:36:44.733215Z",
     "shell.execute_reply.started": "2024-08-21T07:36:30.185871Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,Input\n",
    "from keras.layers import Convolution3D,Conv3D,Add,concatenate, MaxPool3D,add, Convolution2D,BatchNormalization, GlobalAveragePooling3D, ZeroPadding3D\n",
    "from keras import backend as K\n",
    "import cv2\n",
    "import operator\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from scipy.ndimage import rotate\n",
    "import random\n",
    "import nibabel as nib\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from matplotlib import animation, rc\n",
    "from scipy.ndimage import rotate\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import KFold, StratifiedKFold,train_test_split\n",
    "from scipy.ndimage import zoom\n",
    "from matplotlib.patches import PathPatch, Rectangle\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T07:36:44.735426Z",
     "iopub.status.busy": "2024-08-21T07:36:44.735012Z",
     "iopub.status.idle": "2024-08-21T07:36:53.106971Z",
     "shell.execute_reply": "2024-08-21T07:36:53.106037Z",
     "shell.execute_reply.started": "2024-08-21T07:36:44.735400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Enable TPU\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print(\"Device:\", tpu.master())\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T07:36:53.109081Z",
     "iopub.status.busy": "2024-08-21T07:36:53.108830Z",
     "iopub.status.idle": "2024-08-21T07:36:53.121829Z",
     "shell.execute_reply": "2024-08-21T07:36:53.121007Z",
     "shell.execute_reply.started": "2024-08-21T07:36:53.109055Z"
    }
   },
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(32,(3,3,3), activation='relu', kernel_initializer='he_uniform', padding='same',input_shape=(32,32,32,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv3D(32, (3, 3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool3D((2, 2,2)))\n",
    "\n",
    "    \n",
    "    model.add(Conv3D(64, (3, 3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv3D(64, (3, 3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool3D((2, 2,2)))\n",
    "    \n",
    "    model.add(Conv3D(128, (3, 3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv3D(128, (3, 3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool3D((2, 2,2)))\n",
    "    \n",
    "    model.add(Conv3D(128, (3, 3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv3D(128, (3, 3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv3D(128, (3, 3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv3D(128, (3, 3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool3D((2, 2,2)))\n",
    "\n",
    "    model.add(Conv3D(256, (3, 3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv3D(256, (3, 3,3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(8, activation='relu', kernel_initializer='he_uniform'))\n",
    "\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer='he_uniform'));\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Luna Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T07:36:53.123014Z",
     "iopub.status.busy": "2024-08-21T07:36:53.122730Z",
     "iopub.status.idle": "2024-08-21T07:36:54.594347Z",
     "shell.execute_reply": "2024-08-21T07:36:54.593135Z",
     "shell.execute_reply.started": "2024-08-21T07:36:53.122987Z"
    }
   },
   "outputs": [],
   "source": [
    "luna_df = pd.read_excel('/kaggle/input/spie-cropped-resampled-dataset/final_Luna16.xlsx')\n",
    "column_luna = 'malignancy'\n",
    "luna_series=luna_df['Series Uid'].tolist()\n",
    "\n",
    "luna_folder = '/kaggle/input/spie-cropped-resampled-dataset/Luna_16_cropped_resampled/Luna_16_cropped_resampled'  \n",
    "luna = []\n",
    "for i in luna_series:\n",
    "    nii_file_path = os.path.join(luna_folder, f'{i}.nii')  # Assuming NII files have the extension '.nii'\n",
    "    \n",
    "    if os.path.exists(nii_file_path):\n",
    "        luna.append(i)\n",
    "luna=np.array(luna)\n",
    "\n",
    "print(luna.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unlabeled load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T07:36:54.595865Z",
     "iopub.status.busy": "2024-08-21T07:36:54.595538Z",
     "iopub.status.idle": "2024-08-21T07:36:55.618176Z",
     "shell.execute_reply": "2024-08-21T07:36:55.617006Z",
     "shell.execute_reply.started": "2024-08-21T07:36:54.595837Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the Excel file for unlabeled_df\n",
    "unlabeled_df = pd.read_excel('/kaggle/input/semi-testtrainval/combined_correct_predictions.xlsx')\n",
    "column_unlabeled = 'malignancy'\n",
    "unlabeled_series = unlabeled_df['scan'].tolist()\n",
    "\n",
    "unlabeled_folder = '/kaggle/input/spie-cropped-resampled-dataset/Luna_16_cropped_resampled/Luna_16_cropped_resampled'\n",
    "unlabeled = []\n",
    "for i in unlabeled_series:\n",
    "    nii_file_path = os.path.join(unlabeled_folder, f'{i}.nii')\n",
    "    \n",
    "    if os.path.exists(nii_file_path):\n",
    "        unlabeled.append(i)\n",
    "unlabeled = np.array(unlabeled)\n",
    "\n",
    "print(unlabeled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T07:36:55.619493Z",
     "iopub.status.busy": "2024-08-21T07:36:55.619219Z",
     "iopub.status.idle": "2024-08-21T07:36:55.623217Z",
     "shell.execute_reply": "2024-08-21T07:36:55.622333Z",
     "shell.execute_reply.started": "2024-08-21T07:36:55.619467Z"
    }
   },
   "outputs": [],
   "source": [
    "BS= 48 # batch size\n",
    "E = 200 #epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T07:36:55.624465Z",
     "iopub.status.busy": "2024-08-21T07:36:55.624189Z",
     "iopub.status.idle": "2024-08-21T07:36:55.635759Z",
     "shell.execute_reply": "2024-08-21T07:36:55.635010Z",
     "shell.execute_reply.started": "2024-08-21T07:36:55.624419Z"
    }
   },
   "outputs": [],
   "source": [
    "def aug_rotate(x):\n",
    "\n",
    "    rotated_slices = []\n",
    "    for slice_idx in range(x.shape[2]):\n",
    "        slice_data = x[:, :, slice_idx]  # Extract a single slice\n",
    "        rotated_slice = rotate(slice_data, angle=angles[j], reshape=False, mode='nearest')\n",
    "        rotated_slices.append(rotated_slice)\n",
    "\n",
    "    # Create a new NIfTI image from the rotated slices\n",
    "    rotated_img_data = np.stack(rotated_slices, axis=-1)\n",
    "    # Create a new NIfTI image using the header information from the original image\n",
    "    rotated_nifti = nib.Nifti1Image(rotated_img_data, img.affine)\n",
    "    \n",
    "    return rotated_nifti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T07:36:55.636814Z",
     "iopub.status.busy": "2024-08-21T07:36:55.636603Z",
     "iopub.status.idle": "2024-08-21T07:36:55.712376Z",
     "shell.execute_reply": "2024-08-21T07:36:55.711647Z",
     "shell.execute_reply.started": "2024-08-21T07:36:55.636792Z"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the path to the Excel file\n",
    "file_path = '/kaggle/input/semi-testtrainval/test_train_vai_set.xlsx'\n",
    "# Load the Excel file\n",
    "df = pd.read_excel(file_path)\n",
    "# z_train\n",
    "\n",
    "z_train = df.iloc[:, 2]    # Third column\n",
    "\n",
    "#z_test\n",
    "z_test_fixed = df.iloc[:, 0]  # First column\n",
    "nan_count = z_test_fixed.isna().sum()\n",
    "z_test = z_test_fixed.dropna()\n",
    "\n",
    "#z_val\n",
    "z_val_fixed = df.iloc[:, 1]  # Second column\n",
    "nan_count_val = z_val_fixed.isna().sum()\n",
    "z_val = z_val_fixed.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T07:36:55.715426Z",
     "iopub.status.busy": "2024-08-21T07:36:55.715192Z",
     "iopub.status.idle": "2024-08-21T07:36:55.719575Z",
     "shell.execute_reply": "2024-08-21T07:36:55.718839Z",
     "shell.execute_reply.started": "2024-08-21T07:36:55.715403Z"
    }
   },
   "outputs": [],
   "source": [
    "datas_test = []\n",
    "labels_test = []\n",
    "scans_test = []\n",
    "\n",
    "datas_train = []\n",
    "labels_train = []\n",
    "scans_train = []\n",
    "\n",
    "datas_val = []\n",
    "labels_val = []\n",
    "scans_val = []\n",
    "angles = [0, 45, 90, 135, 180, 225, 270, 315]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T07:38:51.472962Z",
     "iopub.status.busy": "2024-08-21T07:38:51.472500Z",
     "iopub.status.idle": "2024-08-21T07:38:51.479552Z",
     "shell.execute_reply": "2024-08-21T07:38:51.478609Z",
     "shell.execute_reply.started": "2024-08-21T07:38:51.472932Z"
    }
   },
   "outputs": [],
   "source": [
    "print(z_train.shape)\n",
    "print(z_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T07:39:28.990240Z",
     "iopub.status.busy": "2024-08-21T07:39:28.989823Z",
     "iopub.status.idle": "2024-08-21T07:41:00.649366Z",
     "shell.execute_reply": "2024-08-21T07:41:00.648462Z",
     "shell.execute_reply.started": "2024-08-21T07:39:28.990210Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in z_train:  # Assuming i is a value in the first column\n",
    "    matching_rows_luna = luna_df.loc[luna_df['Series Uid'] == i, 'malignancy']\n",
    "    matching_rows_unlabeled = unlabeled_df.loc[unlabeled_df['scan'] == i, 'malignancy']\n",
    "    if not matching_rows_luna.empty:\n",
    "        lab = matching_rows_luna.values[0]\n",
    "        img_files = glob.glob(os.path.join(\n",
    "            \"/kaggle/input/spie-cropped-resampled-dataset/Luna_16_cropped_resampled/Luna_16_cropped_resampled/\",\n",
    "            i + \"*.nii\"\n",
    "        ))\n",
    "\n",
    "        for img_file in img_files:\n",
    "            img = nib.load(img_file)\n",
    "            data = img.get_fdata()\n",
    "            for j in range(len(angles)):\n",
    "                rotated_nifti = aug_rotate(data)\n",
    "                datas_train.append(rotated_nifti.get_fdata())\n",
    "                labels_train.append(lab)\n",
    "\n",
    "    elif not matching_rows_unlabeled.empty:\n",
    "        lab = matching_rows_unlabeled.values[0]\n",
    "        img_files = glob.glob(os.path.join(\n",
    "            \"/kaggle/input/spie-cropped-resampled-dataset/Luna_16_cropped_resampled/Luna_16_cropped_resampled/\",\n",
    "            i + \"*.nii\"\n",
    "        ))\n",
    "\n",
    "        for img_file in img_files:\n",
    "            img = nib.load(img_file)\n",
    "            data = img.get_fdata()\n",
    "            for j in range(len(angles)):\n",
    "                rotated_nifti = aug_rotate(data)\n",
    "                datas_train.append(rotated_nifti.get_fdata())\n",
    "                labels_train.append(lab)\n",
    "    else:\n",
    "        print(f\"No matching Series Uid found for: {i}\")\n",
    "X_train = np.array(datas_train)\n",
    "y_train = np.array(labels_train)\n",
    "\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T07:41:05.634771Z",
     "iopub.status.busy": "2024-08-21T07:41:05.634317Z",
     "iopub.status.idle": "2024-08-21T07:41:08.455240Z",
     "shell.execute_reply": "2024-08-21T07:41:08.454066Z",
     "shell.execute_reply.started": "2024-08-21T07:41:05.634730Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in z_val:\n",
    "    lab = luna_df.loc[luna_df['Series Uid'] == i, 'malignancy'].values[0]\n",
    "    img_files = glob.glob(os.path.join(luna_folder, f\"{i}.nii\"))\n",
    "    for img_file in img_files:\n",
    "        img = nib.load(img_file)\n",
    "        data = img.get_fdata()\n",
    "        datas_val.append(data)\n",
    "        labels_val.append(lab)\n",
    "\n",
    "for i in z_test:\n",
    "    lab = luna_df.loc[luna_df['Series Uid'] == i, 'malignancy'].values[0]\n",
    "    img_files = glob.glob(os.path.join(luna_folder, f\"{i}.nii\"))\n",
    "    for img_file in img_files:\n",
    "        img = nib.load(img_file)\n",
    "        data = img.get_fdata()\n",
    "        datas_test.append(data)\n",
    "        labels_test.append(lab)\n",
    "            \n",
    "\n",
    "X_test = np.array(datas_test)\n",
    "y_test = np.array(labels_test)\n",
    "X_val = np.array(datas_val)\n",
    "y_val = np.array(labels_val)\n",
    "\n",
    "\n",
    "X_train = np.array(datas_train)\n",
    "y_train = np.array(labels_train)\n",
    "X_test = np.array(datas_test)\n",
    "y_test = np.array(labels_test)\n",
    "X_val = np.array(datas_val)\n",
    "y_val = np.array(labels_val)\n",
    "\n",
    "print(y_train.shape, y_test.shape, y_val.shape)\n",
    "print(X_train.shape, X_test.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T07:41:19.933550Z",
     "iopub.status.busy": "2024-08-21T07:41:19.933140Z",
     "iopub.status.idle": "2024-08-21T07:41:19.947632Z",
     "shell.execute_reply": "2024-08-21T07:41:19.946717Z",
     "shell.execute_reply.started": "2024-08-21T07:41:19.933519Z"
    }
   },
   "outputs": [],
   "source": [
    "def conv_block(inputs):\n",
    "    x = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPool3D((2, 2, 2))(x)\n",
    "    \n",
    "    x = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPool3D((2, 2, 2))(x)\n",
    "    \n",
    "    x = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPool3D((2, 2, 2))(x)\n",
    "    \n",
    "    x = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPool3D((2, 2, 2))(x)\n",
    "    \n",
    "    x = Conv3D(256, (3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv3D(256, (3, 3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPool3D((2, 2, 2))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def define_model2(num_branches):\n",
    "    input_shape = (32, 32, 32, 1)\n",
    "    inputs = [Input(shape=input_shape) for _ in range(num_branches)]\n",
    "\n",
    "    branches = [conv_block(inputs[i]) for i in range(num_branches)]\n",
    "    #x = Add()(branches)\n",
    "    x = concatenate(branches)\n",
    "\n",
    "    x = Dense(128, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(64, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(32, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(8, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "\n",
    "    outputs = Dense(1, activation='sigmoid', kernel_initializer='he_uniform')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T09:35:20.364282Z",
     "iopub.status.busy": "2024-01-09T09:35:20.363845Z",
     "iopub.status.idle": "2024-01-09T09:35:20.375154Z",
     "shell.execute_reply": "2024-01-09T09:35:20.373953Z",
     "shell.execute_reply.started": "2024-01-09T09:35:20.364255Z"
    }
   },
   "source": [
    "# try 1(0.1 diff without no overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T07:41:38.194713Z",
     "iopub.status.busy": "2024-08-21T07:41:38.194272Z",
     "iopub.status.idle": "2024-08-21T07:42:06.586178Z",
     "shell.execute_reply": "2024-08-21T07:42:06.584992Z",
     "shell.execute_reply.started": "2024-08-21T07:41:38.194681Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_division(data, start, end):\n",
    "    division = data.copy()\n",
    "    division[(division > end)] = 1\n",
    "    division = ((division - start) / (end - start)).clip(0, 1)\n",
    "    return division\n",
    "\n",
    "num_divisions = 10\n",
    "start_range = 0.0\n",
    "end_range = 1.0\n",
    "\n",
    "# Training set divisions\n",
    "X_train_divisions = [create_division(X_train, i * (end_range / num_divisions), \n",
    "                     (i + 1) * (end_range / num_divisions)) for i in range(num_divisions)]\n",
    "\n",
    "# Naming the divisions as X_train_1, X_train_2, ..., X_train_10\n",
    "for i in range(1, num_divisions + 1):\n",
    "    locals()[\"X_train_\" + str(i)] = X_train_divisions[i - 1]\n",
    "    \n",
    "# Validation set divisions\n",
    "X_val_divisions = [create_division(X_val, i * (end_range / num_divisions), \n",
    "                    (i + 1) * (end_range / num_divisions)) for i in range(num_divisions)]\n",
    "\n",
    "# Naming the divisions as X_val_1, X_val_2, ..., X_val_10\n",
    "for i in range(1, num_divisions + 1):\n",
    "    locals()[\"X_val_\" + str(i)] = X_val_divisions[i - 1]\n",
    "    \n",
    "# Test set divisions\n",
    "X_test_divisions = [create_division(X_test, i * (end_range / num_divisions), \n",
    "                   (i + 1) * (end_range / num_divisions)) for i in range(num_divisions)]\n",
    "    \n",
    "# Naming the divisions as X_test_1, X_test_2, ..., X_test_10\n",
    "for i in range(1, num_divisions + 1):\n",
    "    locals()[\"X_test_\" + str(i)] = X_test_divisions[i - 1]\n",
    "    \n",
    "X_train_11= X_train.copy()\n",
    "X_val_11= X_val.copy()\n",
    "X_test_11= X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T07:42:38.665873Z",
     "iopub.status.busy": "2024-08-21T07:42:38.664767Z",
     "iopub.status.idle": "2024-08-21T08:37:04.781795Z",
     "shell.execute_reply": "2024-08-21T08:37:04.780722Z",
     "shell.execute_reply.started": "2024-08-21T07:42:38.665831Z"
    }
   },
   "outputs": [],
   "source": [
    "branch= 11\n",
    "\n",
    "# Build model.\n",
    "with strategy.scope():\n",
    "    model=define_model2(branch)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.001,\n",
    "    patience=5,\n",
    "    min_lr=1e-6)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint('HU1.h5', monitor='val_accuracy',save_best_only=True)\n",
    "\n",
    "# Define the early stopping callback to stop training if validation loss does not improve\n",
    "early_stopping_callback = EarlyStopping(monitor='val_accuracy', patience=70)\n",
    "\n",
    "BATCH_SIZE_TPU = BS * strategy.num_replicas_in_sync\n",
    "    \n",
    "history = model.fit([X_train_1, X_train_2, X_train_3, X_train_4, X_train_5,X_train_6 ,X_train_7,X_train_8,\n",
    "                     X_train_9,X_train_10,X_train_11], y_train, validation_data=([X_val_1, X_val_2, X_val_3,\n",
    "                     X_val_4, X_val_5,X_val_6,X_val_7,X_val_8,X_val_9,X_val_10,X_val_11], y_val), epochs=E, \n",
    "                     batch_size=BATCH_SIZE_TPU, callbacks=[checkpoint_callback, lr_callback,early_stopping_callback],verbose=0)\n",
    "\n",
    "# Evaluate the model - report accuracy and capture it into a list for future reporting\n",
    "best_model1 = tf.keras.models.load_model('HU1.h5')\n",
    "\n",
    "    \n",
    "loss1, accuracy1 = best_model1.evaluate([X_test_1, X_test_2, X_test_3, X_test_4, X_test_5,X_test_6,\n",
    "                                         X_test_7,X_test_8,X_test_9,X_test_10,X_test_11], y_test)\n",
    "\n",
    "print(f\"accuracy: {accuracy1*100:.4f}\")\n",
    "print(f\"loss: {loss1*100:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T08:52:03.019777Z",
     "iopub.status.busy": "2024-08-21T08:52:03.019412Z",
     "iopub.status.idle": "2024-08-21T08:52:10.810850Z",
     "shell.execute_reply": "2024-08-21T08:52:10.810046Z",
     "shell.execute_reply.started": "2024-08-21T08:52:03.019750Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "predictions = best_model1.predict([X_test_1, X_test_2, X_test_3, X_test_4, X_test_5,\n",
    "                                   X_test_6, X_test_7, X_test_8, X_test_9, X_test_10, \n",
    "                                   X_test_11])\n",
    "\n",
    "predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Classification Report with precision, recall, f1-score in 4 digits\n",
    "class_names = ['benign', 'malignant']\n",
    "report_dict = classification_report(y_test, predicted_classes, target_names=class_names, output_dict=True)\n",
    "\n",
    "# Convert the report to a DataFrame and format the floating points\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "report_df[['precision', 'recall', 'f1-score']] = report_df[['precision', 'recall', 'f1-score']].applymap(lambda x: f\"{x:.4f}\")\n",
    "\n",
    "print(\"Classification Report:\\n\", report_df)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, predicted_classes)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# AUC\n",
    "auc_score = roc_auc_score(y_test, predictions)\n",
    "print(f\"AUC: {auc_score:.4f}\")\n",
    "\n",
    "# Summarize history for accuracy\n",
    "print(history.history.keys())\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T09:38:18.997354Z",
     "iopub.status.busy": "2024-01-09T09:38:18.996674Z",
     "iopub.status.idle": "2024-01-09T09:38:19.001449Z",
     "shell.execute_reply": "2024-01-09T09:38:19.000415Z",
     "shell.execute_reply.started": "2024-01-09T09:38:18.997313Z"
    }
   },
   "source": [
    "# try 2 (0.2 diff with no overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T08:52:41.165881Z",
     "iopub.status.busy": "2024-08-21T08:52:41.165519Z",
     "iopub.status.idle": "2024-08-21T08:52:55.894524Z",
     "shell.execute_reply": "2024-08-21T08:52:55.893706Z",
     "shell.execute_reply.started": "2024-08-21T08:52:41.165850Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_division(data, start, end):\n",
    "    division = data.copy()\n",
    "    division[(division > end)] = 1\n",
    "    division = ((division - start) / (end - start)).clip(0, 1)\n",
    "    return division\n",
    "\n",
    "num_divisions = 5\n",
    "start_range = 0.0\n",
    "end_range = 1.0\n",
    "\n",
    "# Training set divisions\n",
    "X_train_divisions = [create_division(X_train, i * (end_range / num_divisions), \n",
    "                     (i + 1) * (end_range / num_divisions)) for i in range(num_divisions)]\n",
    "\n",
    "# Naming the divisions as X_train_1, X_train_2, ..., X_train_5\n",
    "for i in range(1, num_divisions + 1):\n",
    "    locals()[\"X_train_\" + str(i)] = X_train_divisions[i - 1]\n",
    "    \n",
    "# Validation set divisions\n",
    "X_val_divisions = [create_division(X_val, i * (end_range / num_divisions), \n",
    "                    (i + 1) * (end_range / num_divisions)) for i in range(num_divisions)]\n",
    "\n",
    "# Naming the divisions as X_val_1, X_val_2, ..., X_val_5\n",
    "for i in range(1, num_divisions + 1):\n",
    "    locals()[\"X_val_\" + str(i)] = X_val_divisions[i - 1]\n",
    "    \n",
    "# Test set divisions\n",
    "X_test_divisions = [create_division(X_test, i * (end_range / num_divisions), \n",
    "                   (i + 1) * (end_range / num_divisions)) for i in range(num_divisions)]\n",
    "    \n",
    "# Naming the divisions as X_test_1, X_test_2, ..., X_test_5\n",
    "for i in range(1, num_divisions + 1):\n",
    "    locals()[\"X_test_\" + str(i)] = X_test_divisions[i - 1]\n",
    "    \n",
    "X_train_6= X_train.copy()\n",
    "X_val_6= X_val.copy()\n",
    "X_test_6= X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T08:53:04.634953Z",
     "iopub.status.busy": "2024-08-21T08:53:04.634631Z",
     "iopub.status.idle": "2024-08-21T09:19:46.129170Z",
     "shell.execute_reply": "2024-08-21T09:19:46.128040Z",
     "shell.execute_reply.started": "2024-08-21T08:53:04.634926Z"
    }
   },
   "outputs": [],
   "source": [
    "branch= 6\n",
    "\n",
    "# Build model.\n",
    "with strategy.scope():\n",
    "    model=define_model2(branch)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.001,\n",
    "    patience=5,\n",
    "    min_lr=1e-6)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint('HU2.h5', monitor='val_accuracy',save_best_only=True)\n",
    "\n",
    "# Define the early stopping callback to stop training if validation loss does not improve\n",
    "early_stopping_callback = EarlyStopping(monitor='val_accuracy', patience=70)\n",
    "\n",
    "BATCH_SIZE_TPU = BS * strategy.num_replicas_in_sync\n",
    "    \n",
    "history = model.fit([X_train_1, X_train_2, X_train_3, X_train_4, X_train_5,X_train_6], y_train, \n",
    "                    validation_data=([X_val_1, X_val_2, X_val_3, X_val_4, X_val_5,X_val_6], y_val), \n",
    "                    epochs=E, batch_size=BATCH_SIZE_TPU, callbacks=[checkpoint_callback, lr_callback,early_stopping_callback],verbose=0)\n",
    "\n",
    "# Evaluate the model - report accuracy and capture it into a list for future reporting\n",
    "best_model2 = tf.keras.models.load_model('HU2.h5')\n",
    "\n",
    "    \n",
    "loss2, accuracy2 = best_model2.evaluate([X_test_1, X_test_2, X_test_3, X_test_4, X_test_5,X_test_6], y_test)\n",
    "\n",
    "print(f\"accuracy: {accuracy2*100:.4f}\")\n",
    "print(f\"loss: {loss2*100:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T09:22:08.519538Z",
     "iopub.status.busy": "2024-08-21T09:22:08.519157Z",
     "iopub.status.idle": "2024-08-21T09:22:14.364484Z",
     "shell.execute_reply": "2024-08-21T09:22:14.363415Z",
     "shell.execute_reply.started": "2024-08-21T09:22:08.519508Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "predictions = best_model2.predict([X_test_1, X_test_2, X_test_3, X_test_4, X_test_5, X_test_6])\n",
    "predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Classification Report with precision, recall, f1-score in 4 digits\n",
    "class_names = ['benign', 'malignant']\n",
    "report_dict = classification_report(y_test, predicted_classes, target_names=class_names, output_dict=True)\n",
    "\n",
    "# Convert the report to a DataFrame and format the floating points\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "report_df[['precision', 'recall', 'f1-score']] = report_df[['precision', 'recall', 'f1-score']].applymap(lambda x: f\"{x:.4f}\")\n",
    "\n",
    "print(\"Classification Report:\\n\", report_df)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, predicted_classes)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# AUC\n",
    "auc_score = roc_auc_score(y_test, predictions)\n",
    "print(f\"AUC: {auc_score:.4f}\")\n",
    "\n",
    "# Summarize history for accuracy\n",
    "print(history.history.keys())\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try 4 (0.5 diff with no overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T09:24:30.373678Z",
     "iopub.status.busy": "2024-08-21T09:24:30.373213Z",
     "iopub.status.idle": "2024-08-21T09:24:36.472515Z",
     "shell.execute_reply": "2024-08-21T09:24:36.471507Z",
     "shell.execute_reply.started": "2024-08-21T09:24:30.373647Z"
    }
   },
   "outputs": [],
   "source": [
    "branch = 3\n",
    "\n",
    "X_train_1 = X_train.copy()\n",
    "X_train_1[X_train_1 > 0.5] = 1\n",
    "X_train_1 = (X_train_1 / 0.5).clip(0, 1)\n",
    "\n",
    "X_train_2 = X_train.copy()  # Make a copy to avoid modifying the original array\n",
    "X_train_2 = ((X_train_2 - 0.5) / 0.5).clip(0, 1)\n",
    "X_train_3 = X_train.copy()  \n",
    "\n",
    "\n",
    "\n",
    "X_val_1 = X_val.copy()\n",
    "X_val_1[X_val_1 > 0.5] = 1\n",
    "X_val_1 = (X_val_1 / 0.5).clip(0, 1)\n",
    "\n",
    "X_val_2 = X_val.copy()  # Make a copy to avoid modifying the original array\n",
    "X_val_2 = ((X_val_2 - 0.5) / 0.5).clip(0, 1)\n",
    "X_val_3 = X_val.copy()  \n",
    "\n",
    "\n",
    "\n",
    "X_test_1 = X_test.copy()\n",
    "X_test_1[X_test_1 > 0.5] = 1\n",
    "X_test_1 = (X_test_1 / 0.5).clip(0, 1)\n",
    "\n",
    "X_test_2 = X_test.copy()  # Make a copy to avoid modifying the original array\n",
    "X_test_2 = ((X_test_2 - 0.5) / 0.5).clip(0, 1)\n",
    "X_test_3 = X_test.copy()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T09:24:43.995580Z",
     "iopub.status.busy": "2024-08-21T09:24:43.995230Z",
     "iopub.status.idle": "2024-08-21T09:49:21.280978Z",
     "shell.execute_reply": "2024-08-21T09:49:21.279939Z",
     "shell.execute_reply.started": "2024-08-21T09:24:43.995552Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build model.\n",
    "with strategy.scope():\n",
    "    model=define_model2(branch)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.001,\n",
    "    patience=5,\n",
    "    min_lr=1e-6)\n",
    "\n",
    "# Define the early stopping callback to stop training if validation loss does not improve\n",
    "early_stopping_callback = EarlyStopping(monitor='val_accuracy', patience=70)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint('HU4.h5', monitor='val_accuracy',save_best_only=True)\n",
    "\n",
    "\n",
    "BATCH_SIZE_TPU = BS * strategy.num_replicas_in_sync\n",
    "    \n",
    "history = model.fit([X_train_1, X_train_2, X_train_3], y_train, \n",
    "                    validation_data=([X_val_1, X_val_2, X_val_3], y_val), \n",
    "                    epochs=E, batch_size=BATCH_SIZE_TPU, callbacks=[checkpoint_callback, lr_callback,early_stopping_callback],verbose=0)\n",
    "\n",
    "# Evaluate the model - report accuracy and capture it into a list for future reporting\n",
    "best_model4 = tf.keras.models.load_model('HU4.h5')\n",
    "\n",
    "    \n",
    "loss4, accuracy4 = best_model4.evaluate([X_test_1, X_test_2, X_test_3], y_test)\n",
    "\n",
    "print(f\"accuracy: {accuracy4*100:.4f}\")\n",
    "print(f\"loss: {loss4*100:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T09:50:01.288785Z",
     "iopub.status.busy": "2024-08-21T09:50:01.288409Z",
     "iopub.status.idle": "2024-08-21T09:50:04.410908Z",
     "shell.execute_reply": "2024-08-21T09:50:04.410023Z",
     "shell.execute_reply.started": "2024-08-21T09:50:01.288757Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "predictions = best_model4.predict([X_test_1, X_test_2, X_test_3])\n",
    "predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Classification Report with precision, recall, f1-score in 4 digits\n",
    "class_names = ['benign', 'malignant']\n",
    "report_dict = classification_report(y_test, predicted_classes, target_names=class_names, output_dict=True)\n",
    "\n",
    "# Convert the report to a DataFrame and format the floating points\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "report_df[['precision', 'recall', 'f1-score']] = report_df[['precision', 'recall', 'f1-score']].applymap(lambda x: f\"{x:.4f}\")\n",
    "\n",
    "print(\"Classification Report:\\n\", report_df)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, predicted_classes)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# AUC\n",
    "auc_score = roc_auc_score(y_test, predictions)\n",
    "print(f\"AUC: {auc_score:.4f}\")\n",
    "\n",
    "# Summarize history for accuracy\n",
    "print(history.history.keys())\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-21T09:50:14.442867Z",
     "iopub.status.busy": "2024-08-21T09:50:14.442536Z",
     "iopub.status.idle": "2024-08-21T09:50:14.447754Z",
     "shell.execute_reply": "2024-08-21T09:50:14.446940Z",
     "shell.execute_reply.started": "2024-08-21T09:50:14.442840Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"HU Accuracy (0.1 diff without overlap): {accuracy1*100:.4f}\")\n",
    "print(f\"HU Accuracy (0.2 diff without overlap): {accuracy2*100:.4f}\")\n",
    "print(f\"HU Accuracy (0.5 diff without overlap): {accuracy4*100:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "datasetId": 3974254,
     "sourceId": 7321302,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5536429,
     "sourceId": 9212708,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30628,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
