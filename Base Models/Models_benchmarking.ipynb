{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd43e15-5e02-4658-8fc9-68365ec8db77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution3D,Conv3D,Add,Concatenate, MaxPool3D,LeakyReLU,add, Convolution2D,BatchNormalization,AveragePooling3D, GlobalAveragePooling3D, ZeroPadding3D\n",
    "from keras import backend as K\n",
    "import cv2\n",
    "import operator\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from scipy.ndimage import rotate\n",
    "import random\n",
    "import nibabel as nib\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from matplotlib import animation, rc\n",
    "from scipy.ndimage import rotate\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import KFold, StratifiedKFold,train_test_split\n",
    "from scipy.ndimage import zoom\n",
    "from matplotlib.patches import PathPatch, Rectangle\n",
    "from IPython.display import HTML\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20005c64-6b4f-49ae-b09d-9c01692c8650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "\n",
    "print(\"Using GPU:\", gpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6a7b0f-44c7-4117-a86d-9e9b6831efd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "luna_df = pd.read_excel('/home/m-health/TBM/Lung/final_Luna16.xlsx')\n",
    "column_luna = 'malignancy'\n",
    "luna_series=luna_df['Series Uid'].tolist()\n",
    "\n",
    "luna_folder = '/home/m-health/TBM/Lung/Luna_16_hu_from_crop_32'  \n",
    "luna = []\n",
    "for i in luna_series:\n",
    "    nii_file_path = os.path.join(luna_folder, f'{i}.nii')  # Assuming NII files have the extension '.nii'\n",
    "    \n",
    "    if os.path.exists(nii_file_path):\n",
    "        luna.append(i)\n",
    "luna=np.array(luna)\n",
    "\n",
    "print(luna.shape)\n",
    "\n",
    "# Specify the path to the Excel file\n",
    "file_path = '/home/m-health/TBM/Lung/test_initialtrain_vai_set.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "z_train = df.iloc[:, 2]  \n",
    "\n",
    "z_test_fixed = df.iloc[:, 0]  \n",
    "nan_count = z_test_fixed.isna().sum()\n",
    "z_test = z_test_fixed.dropna()\n",
    "\n",
    "z_val_fixed = df.iloc[:, 1]  \n",
    "nan_count_val = z_val_fixed.isna().sum()\n",
    "z_val = z_val_fixed.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9612958-d402-4a08-b3ea-c08372956e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "BS= 16 # batch size\n",
    "E = 200 #epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daa87fb-0d7f-4d8f-a752-fb3c4658bf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug_rotate(x):\n",
    "\n",
    "    rotated_slices = []\n",
    "    for slice_idx in range(x.shape[2]):\n",
    "        slice_data = x[:, :, slice_idx]  # Extract a single slice\n",
    "        rotated_slice = rotate(slice_data, angle=angles[j], reshape=False, mode='nearest')\n",
    "        rotated_slices.append(rotated_slice)\n",
    "\n",
    "    # Create a new NIfTI image from the rotated slices\n",
    "    rotated_img_data = np.stack(rotated_slices, axis=-1)\n",
    "    # Create a new NIfTI image using the header information from the original image\n",
    "    rotated_nifti = nib.Nifti1Image(rotated_img_data, img.affine)\n",
    "    \n",
    "    return rotated_nifti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07c7bb6-f63d-480f-90e7-78c6ce5f5814",
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = [0, 45, 90, 135, 180, 225, 270, 315]\n",
    "\n",
    "\n",
    "\n",
    "datas_test = []\n",
    "labels_test = []\n",
    "scans_test = []\n",
    "\n",
    "datas_train = []\n",
    "labels_train = []\n",
    "scans_train = []\n",
    "\n",
    "datas_val = []\n",
    "labels_val = []\n",
    "scans_val = []\n",
    "\n",
    "\n",
    "for i in z_train:\n",
    "    lab = luna_df.loc[luna_df['Series Uid'] == i, 'malignancy'].values[0]\n",
    "    img_files = glob.glob(os.path.join(luna_folder, f\"{i}.nii\"))\n",
    "    for img_file in img_files:\n",
    "        img = nib.load(img_file)\n",
    "        data = img.get_fdata()\n",
    "        for j in range(len(angles)):\n",
    "            rotated_nifti = aug_rotate(data)\n",
    "            datas_train.append(rotated_nifti.get_fdata())\n",
    "            labels_train.append(lab)\n",
    "                    \n",
    "for i in z_val:\n",
    "    lab = luna_df.loc[luna_df['Series Uid'] == i, 'malignancy'].values[0]\n",
    "    img_files = glob.glob(os.path.join(luna_folder, f\"{i}.nii\"))\n",
    "    for img_file in img_files:\n",
    "        img = nib.load(img_file)\n",
    "        data = img.get_fdata()\n",
    "        datas_val.append(data)\n",
    "        labels_val.append(lab)\n",
    "\n",
    "for i in z_test:\n",
    "    lab = luna_df.loc[luna_df['Series Uid'] == i, 'malignancy'].values[0]\n",
    "    img_files = glob.glob(os.path.join(luna_folder, f\"{i}.nii\"))\n",
    "    for img_file in img_files:\n",
    "        img = nib.load(img_file)\n",
    "        data = img.get_fdata()\n",
    "        datas_test.append(data)\n",
    "        labels_test.append(lab)\n",
    "            \n",
    "X_train = np.array(datas_train)\n",
    "y_train = np.array(labels_train)\n",
    "X_test = np.array(datas_test)\n",
    "y_test = np.array(labels_test)\n",
    "X_val = np.array(datas_val)\n",
    "y_val = np.array(labels_val)\n",
    "\n",
    "\n",
    "X_train = np.array(datas_train)\n",
    "y_train = np.array(labels_train)\n",
    "X_test = np.array(datas_test)\n",
    "y_test = np.array(labels_test)\n",
    "X_val = np.array(datas_val)\n",
    "y_val = np.array(labels_val)\n",
    "\n",
    "print(z_train.shape, z_test.shape, z_val.shape)\n",
    "print(X_train.shape, X_test.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b8054b-6ce7-4a69-8e2e-2339f3f15a7a",
   "metadata": {},
   "source": [
    "# DenseNet3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f68f98-c7d1-49a1-a414-20cb3dfb78f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, GlobalAveragePooling3D, GlobalMaxPooling3D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3D Dense Layer\n",
    "# -------------------------------------------------------------\n",
    "def dense_layer(x, growth_rate, bottleneck=True, dropout_rate=0.0):\n",
    "    \"\"\"One 3D Dense Layer: BN → ReLU → Conv1x1x1 → BN → ReLU → Conv3x3x3\"\"\"\n",
    "    \n",
    "    if bottleneck:\n",
    "        # Bottleneck 1x1x1\n",
    "        x1 = layers.BatchNormalization()(x)\n",
    "        x1 = layers.ReLU()(x1)\n",
    "        x1 = layers.Conv3D(4 * growth_rate, kernel_size=1, use_bias=False)(x1)\n",
    "    else:\n",
    "        x1 = x\n",
    "\n",
    "    # 3x3x3 conv\n",
    "    x1 = layers.BatchNormalization()(x1)\n",
    "    x1 = layers.ReLU()(x1)\n",
    "    x1 = layers.Conv3D(growth_rate, kernel_size=3, padding=\"same\", use_bias=False)(x1)\n",
    "\n",
    "    if dropout_rate:\n",
    "        x1 = layers.Dropout(dropout_rate)(x1)\n",
    "\n",
    "    # Concatenate input + output (Dense connectivity)\n",
    "    return layers.Concatenate()([x, x1])\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3D Dense Block\n",
    "# -------------------------------------------------------------\n",
    "def dense_block(x, num_layers, growth_rate, bottleneck=True, dropout_rate=0.0):\n",
    "    for _ in range(num_layers):\n",
    "        x = dense_layer(x, growth_rate, bottleneck, dropout_rate)\n",
    "    return x\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Transition Down (Compression)\n",
    "# -------------------------------------------------------------\n",
    "def transition_layer(x, reduction=0.5):\n",
    "    filters = int(tf.keras.backend.int_shape(x)[-1] * reduction)\n",
    "\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv3D(filters, kernel_size=1, use_bias=False)(x)\n",
    "    x = layers.AveragePooling3D(pool_size=2, strides=2)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# DenseNet3D (Main constructor)\n",
    "# -------------------------------------------------------------\n",
    "def DenseNet3D(input_shape=(32, 32, 32, 1),\n",
    "               depth=52,\n",
    "               nb_dense_block=4,\n",
    "               growth_rate=32,\n",
    "               bottleneck=True,\n",
    "               reduction=0.5,\n",
    "               dropout_rate=0.0,\n",
    "               include_top=True,\n",
    "               pooling='avg',\n",
    "               classes=1,\n",
    "               activation='sigmoid'):\n",
    "\n",
    "    \"\"\"\n",
    "    Builds a full 3D DenseNet model.\n",
    "    depth examples: 121, 169, 201 (DenseNet variants)\n",
    "    \"\"\"\n",
    "\n",
    "    # Depth configuration from original DenseNet paper\n",
    "    # Formula: (depth - 4) / 6 gives layers per block (for bottleneck architecture)\n",
    "    assert (depth - 4) % (nb_dense_block * 2) == 0, \"Invalid depth for DenseNet\"\n",
    "    layers_per_block = (depth - 4) // (nb_dense_block * 2)\n",
    "\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Initial convolution\n",
    "    x = layers.Conv3D(64, kernel_size=7, strides=2, padding=\"same\", use_bias=False)(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPooling3D(pool_size=3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "    # Build Dense Blocks\n",
    "    for block in range(nb_dense_block):\n",
    "        x = dense_block(x, layers_per_block, growth_rate, bottleneck, dropout_rate)\n",
    "\n",
    "        if block != nb_dense_block - 1:\n",
    "            x = transition_layer(x, reduction)\n",
    "\n",
    "    # Final BatchNorm\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # Classification head\n",
    "    if include_top:\n",
    "        if pooling == 'avg':\n",
    "            x = layers.GlobalAveragePooling3D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = layers.GlobalMaxPooling3D()(x)\n",
    "        else:\n",
    "            raise ValueError(\"pooling must be 'avg' or 'max'\")\n",
    "\n",
    "        x = layers.Dense(classes, activation=activation)(x)\n",
    "\n",
    "    model = models.Model(inputs, x, name=f\"DenseNet3D_{depth}\")\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2a8957-2beb-4ab4-8157-2017af5f7c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"/home/m-health/TBM/Lung/\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "strategy = tf.distribute.get_strategy()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Build & compile model\n",
    "# ------------------------------------------------------------\n",
    "with strategy.scope():\n",
    "    model = DenseNet3D(\n",
    "    input_shape=(32,32,32,1),\n",
    "    depth=52,            # DenseNet-121\n",
    "    classes=1,            # benign vs malignant\n",
    "    pooling='avg',\n",
    "    activation='sigmoid'\n",
    ")\n",
    "    model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',   # or binary_crossentropy if classes=1\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) Callbacks\n",
    "# ------------------------------------------------------------\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.001,\n",
    "    patience=5,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=os.path.join(save_dir, \"densenet.h5\"),\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6) Train\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=E,\n",
    "    batch_size=BS,\n",
    "    callbacks=[lr_callback, checkpoint_callback],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7) Load best model & evaluate\n",
    "# ------------------------------------------------------------\n",
    "best_model = tf.keras.models.load_model(os.path.join(save_dir, \"densenet.h5\"))\n",
    "loss, accuracy = best_model.evaluate(X_test, y_test)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8) Predictions\n",
    "# ------------------------------------------------------------\n",
    "predictions = best_model.predict(X_test)\n",
    "predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "class_names = ['benign', 'malignant']\n",
    "print(classification_report(y_test, predicted_classes, target_names=class_names, digits=5))\n",
    "\n",
    "auc = roc_auc_score(y_test, predictions)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 9) Confusion Matrix\n",
    "# ------------------------------------------------------------\n",
    "cm = confusion_matrix(y_test, predicted_classes)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "print(f'Loss: {loss*100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7077a232-d030-4fb1-bfbf-8952084f8adf",
   "metadata": {},
   "source": [
    "# ConvNeXtTiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34b85ad-a0ed-4a11-b738-260aff2e6ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Smallest ConvNeXt 3D block\n",
    "# -----------------------------------------------------------\n",
    "def convnext_block_3d_tiny(x, dim):\n",
    "    shortcut = x\n",
    "\n",
    "    # Depthwise conv\n",
    "    x = layers.Conv3D(dim, kernel_size=7, padding=\"same\", groups=dim)(x)\n",
    "\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "\n",
    "    # No huge expansion — ONLY 1x\n",
    "    x = layers.Conv3D(dim, kernel_size=1)(x)\n",
    "    x = layers.Activation(\"gelu\")(x)\n",
    "\n",
    "    # Residual\n",
    "    return layers.Add()([shortcut, x])\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Ultra-reduced ConvNeXt for 32³ nodules\n",
    "# -----------------------------------------------------------\n",
    "def ConvNeXt3D_reduced(input_shape=(32,32,32,1)):\n",
    "    \n",
    "    dims = [16, 32, 64, 128]   # drastically reduced\n",
    "    depths = [1, 1, 2, 1]      # minimal blocks\n",
    "\n",
    "    inputs = layers.Input(input_shape)\n",
    "    x = inputs\n",
    "\n",
    "    # Stem\n",
    "    x = layers.Conv3D(dims[0], kernel_size=4, strides=4, padding=\"same\")(x)\n",
    "\n",
    "    # 4 stages\n",
    "    for i in range(4):\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        for _ in range(depths[i]):\n",
    "            x = convnext_block_3d_tiny(x, dims[i])\n",
    "\n",
    "        if i < 3:\n",
    "            x = layers.Conv3D(dims[i+1], kernel_size=2, strides=2, padding=\"same\")(x)\n",
    "\n",
    "    # global pooling\n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    return models.Model(inputs, outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d00e7d-e7be-4ae6-879e-6b6a1e12dd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"/home/m-health/TBM/Lung/\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "strategy = tf.distribute.get_strategy()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Build & compile model\n",
    "\n",
    "# Example usage with TPU/strategy\n",
    "strategy = tf.distribute.get_strategy()\n",
    "with strategy.scope():\n",
    "    model = ConvNeXt3D_reduced()\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) Callbacks\n",
    "# ------------------------------------------------------------\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.001,\n",
    "    patience=5,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=os.path.join(save_dir, \"ConvNeXt.h5\"),\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6) Train\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=E,\n",
    "    batch_size=BS,\n",
    "    callbacks=[lr_callback, checkpoint_callback],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7) Load best model & evaluate\n",
    "# ------------------------------------------------------------\n",
    "best_model = tf.keras.models.load_model(os.path.join(save_dir, \"ConvNeXt.h5\"))\n",
    "loss, accuracy = best_model.evaluate(X_test, y_test)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8) Predictions\n",
    "# ------------------------------------------------------------\n",
    "predictions = best_model.predict(X_test)\n",
    "predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "class_names = ['benign', 'malignant']\n",
    "print(classification_report(y_test, predicted_classes, target_names=class_names, digits=5))\n",
    "\n",
    "auc = roc_auc_score(y_test, predictions)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 9) Confusion Matrix\n",
    "# ------------------------------------------------------------\n",
    "cm = confusion_matrix(y_test, predicted_classes)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "print(f'Loss: {loss*100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfd610f-4ec0-42c1-8faa-f239a47221af",
   "metadata": {},
   "source": [
    "# EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbe5e1c-d779-4fb0-9613-344875ba727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EfficientNetV2B0 3D Keras Implementation\n",
    "from keras import layers, models\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "# ---------------------\n",
    "# MBConv (EfficientNet block)\n",
    "# ---------------------\n",
    "def MBConv3D(inputs, expand_ratio, filters, stride):\n",
    "    in_channels = inputs.shape[-1]\n",
    "    expanded_channels = in_channels * expand_ratio\n",
    "\n",
    "    # 1. Expansion\n",
    "    if expand_ratio != 1:\n",
    "        x = layers.Conv3D(expanded_channels, 1, padding=\"same\")(inputs)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation(\"swish\")(x)\n",
    "    else:\n",
    "        x = inputs\n",
    "\n",
    "    # 2. Depthwise Conv\n",
    "    x = layers.Conv3D(expanded_channels, 3, strides=stride, padding=\"same\", groups=expanded_channels)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"swish\")(x)\n",
    "\n",
    "    # 3. Squeeze & Excitation\n",
    "    se = layers.GlobalAveragePooling3D()(x)\n",
    "    se = layers.Dense(expanded_channels // 4, activation=\"swish\")(se)\n",
    "    se = layers.Dense(expanded_channels, activation=\"sigmoid\")(se)\n",
    "    se = layers.Reshape((1, 1, 1, expanded_channels))(se)\n",
    "    x = layers.Multiply()([x, se])\n",
    "\n",
    "    # 4. Projection\n",
    "    x = layers.Conv3D(filters, 1, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Skip connection\n",
    "    if stride == 1 and in_channels == filters:\n",
    "        x = layers.Add()([inputs, x])\n",
    "    return x\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "# EfficientNet-B0 (3D) – Simplified for small volume (32³)\n",
    "# ---------------------\n",
    "def EfficientNet3D_B0(input_shape=(32,32,32,1), num_classes=1):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Stem\n",
    "    x = layers.Conv3D(16, 3, strides=1, padding=\"same\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"swish\")(x)\n",
    "\n",
    "    # MBConv blocks (extremely reduced for 32³)\n",
    "    x = MBConv3D(x, expand_ratio=1, filters=16, stride=1)\n",
    "    x = MBConv3D(x, expand_ratio=6, filters=24, stride=2)\n",
    "    x = MBConv3D(x, expand_ratio=6, filters=40, stride=2)\n",
    "    x = MBConv3D(x, expand_ratio=6, filters=80, stride=1)\n",
    "\n",
    "    # Head\n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    # Binary classification\n",
    "    if num_classes == 1:\n",
    "        outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    else:\n",
    "        outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3430ca-503b-4298-80c0-8dbae884d861",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"/home/m-health/TBM/Lung/\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "strategy = tf.distribute.get_strategy()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Build & compile model\n",
    "\n",
    "# Example usage with TPU/strategy\n",
    "strategy = tf.distribute.get_strategy()\n",
    "with strategy.scope():\n",
    "    model = EfficientNet3D_B0(input_shape= (32,32,32,1))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) Callbacks\n",
    "# ------------------------------------------------------------\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.001,\n",
    "    patience=5,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=os.path.join(save_dir, \"EfficientNet.h5\"),\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6) Train\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=E,\n",
    "    batch_size=BS,\n",
    "    callbacks=[lr_callback, checkpoint_callback],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7) Load best model & evaluate\n",
    "# ------------------------------------------------------------\n",
    "best_model = tf.keras.models.load_model(os.path.join(save_dir, \"EfficientNet.h5\"))\n",
    "loss, accuracy = best_model.evaluate(X_test, y_test)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8) Predictions\n",
    "# ------------------------------------------------------------\n",
    "predictions = best_model.predict(X_test)\n",
    "predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "class_names = ['benign', 'malignant']\n",
    "print(classification_report(y_test, predicted_classes, target_names=class_names, digits=5))\n",
    "\n",
    "auc = roc_auc_score(y_test, predictions)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 9) Confusion Matrix\n",
    "# ------------------------------------------------------------\n",
    "cm = confusion_matrix(y_test, predicted_classes)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "print(f'Loss: {loss*100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a584318-17b4-4123-b0ba-069024b201c8",
   "metadata": {},
   "source": [
    "# MobileNet V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efc5a29-97b7-4074-b1af-efde3cf28fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "class DepthwiseConv3D(layers.Layer):\n",
    "    def __init__(self, kernel_size, strides=1, padding='same', depth_multiplier=1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "        self.depth_multiplier = depth_multiplier\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.depthwise_conv = layers.Conv3D(\n",
    "            filters=int(input_shape[-1] * self.depth_multiplier),\n",
    "            kernel_size=self.kernel_size,\n",
    "            strides=self.strides,\n",
    "            padding=self.padding,\n",
    "            groups=input_shape[-1],\n",
    "            use_bias=False\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.depthwise_conv(inputs)\n",
    "\n",
    "def inverted_res_block(x, expansion, stride, alpha, filters, block_id):\n",
    "    in_channels = x.shape[-1]\n",
    "    pointwise_filters = int(filters * alpha)\n",
    "\n",
    "    # Expansion\n",
    "    if expansion != 1:\n",
    "        x_exp = layers.Conv3D(expansion * in_channels, 1, padding='same', use_bias=False)(x)\n",
    "        x_exp = layers.BatchNormalization()(x_exp)\n",
    "        x_exp = layers.ReLU(6.)(x_exp)\n",
    "    else:\n",
    "        x_exp = x\n",
    "\n",
    "    # Depthwise\n",
    "    x_exp = DepthwiseConv3D(kernel_size=3, strides=stride, padding='same')(x_exp)\n",
    "    x_exp = layers.BatchNormalization()(x_exp)\n",
    "    x_exp = layers.ReLU(6.)(x_exp)\n",
    "\n",
    "    # Projection\n",
    "    x_proj = layers.Conv3D(pointwise_filters, 1, padding='same', use_bias=False)(x_exp)\n",
    "    x_proj = layers.BatchNormalization()(x_proj)\n",
    "\n",
    "    # Skip connection\n",
    "    if stride == 1 and in_channels == pointwise_filters:\n",
    "        x_proj = layers.Add()([x, x_proj])\n",
    "\n",
    "    return x_proj\n",
    "\n",
    "def MobileNetV2_3D(input_shape=(32,32,32,1), alpha=1.0, classes=1):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    first_filters = int(32 * alpha)\n",
    "\n",
    "    # Stem\n",
    "    x = layers.Conv3D(first_filters, 3, strides=2, padding='same', use_bias=False)(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU(6.)(x)   # 32 → 16\n",
    "\n",
    "    # Blocks\n",
    "    x = inverted_res_block(x, expansion=1, stride=1, alpha=alpha, filters=16, block_id=0)\n",
    "    x = inverted_res_block(x, expansion=6, stride=2, alpha=alpha, filters=24, block_id=1) # 16 → 8\n",
    "    x = inverted_res_block(x, expansion=6, stride=1, alpha=alpha, filters=24, block_id=2)\n",
    "    x = inverted_res_block(x, expansion=6, stride=2, alpha=alpha, filters=32, block_id=3) # 8 → 4\n",
    "    x = inverted_res_block(x, expansion=6, stride=1, alpha=alpha, filters=32, block_id=4)\n",
    "    x = inverted_res_block(x, expansion=6, stride=1, alpha=alpha, filters=32, block_id=5)\n",
    "\n",
    "    # Final Conv\n",
    "    last_filters = 1280 if alpha <= 1 else int(1280 * alpha)\n",
    "    x = layers.Conv3D(last_filters, 1, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU(6.)(x)\n",
    "\n",
    "    # Classifier\n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)  # binary\n",
    "\n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f461a0d-6b88-4737-b08d-0aa5b9c27692",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"/home/m-health/TBM/Lung/\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "strategy = tf.distribute.get_strategy()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Build & compile model\n",
    "\n",
    "with strategy.scope():\n",
    "    model = MobileNetV2_3D(input_shape=(32,32,32,1), alpha=1.0, classes=1)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) Callbacks\n",
    "# ------------------------------------------------------------\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.001,\n",
    "    patience=5,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    # filepath=os.path.join(save_dir, \"MobileNetV2.h5\"),\n",
    "    filepath=os.path.join(save_dir, \"MobileNetV2\"),\n",
    "    save_format=\"tf\",\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6) Train\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=E,\n",
    "    batch_size=BS,\n",
    "    callbacks=[lr_callback, checkpoint_callback],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7) Load best model & evaluate\n",
    "# ------------------------------------------------------------\n",
    "# best_model = tf.keras.models.load_model(os.path.join(save_dir, \"MobileNetV2.h5\"))\n",
    "best_model = tf.keras.models.load_model(os.path.join(save_dir, \"MobileNetV2\"))\n",
    "\n",
    "loss, accuracy = best_model.evaluate(X_test, y_test)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8) Predictions\n",
    "# ------------------------------------------------------------\n",
    "predictions = best_model.predict(X_test)\n",
    "predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "class_names = ['benign', 'malignant']\n",
    "print(classification_report(y_test, predicted_classes, target_names=class_names, digits=5))\n",
    "\n",
    "auc = roc_auc_score(y_test, predictions)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 9) Confusion Matrix\n",
    "# ------------------------------------------------------------\n",
    "cm = confusion_matrix(y_test, predicted_classes)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "print(f'Loss: {loss*100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9ef494-29f0-4833-91fa-625306a1953c",
   "metadata": {},
   "source": [
    "# VGG-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378ad0ee-ea0b-48b5-881e-fe5ce968699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def VGG19_3D_reduced(input_shape=(32,32,32,1), num_classes=1):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # -------------------------\n",
    "    # Block 1\n",
    "    # -------------------------\n",
    "    x = layers.Conv3D(32, 3, padding=\"same\", use_bias=False)(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv3D(32, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)  # 32 -> 16\n",
    "\n",
    "    # -------------------------\n",
    "    # Block 2\n",
    "    # -------------------------\n",
    "    x = layers.Conv3D(64, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv3D(64, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)  # 16 -> 8\n",
    "\n",
    "    # -------------------------\n",
    "    # Block 3\n",
    "    # -------------------------\n",
    "    x = layers.Conv3D(128, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv3D(128, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv3D(128, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv3D(128, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)  # 8 -> 4\n",
    "\n",
    "    # -------------------------\n",
    "    # Block 4\n",
    "    # -------------------------\n",
    "    x = layers.Conv3D(256, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv3D(256, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv3D(256, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv3D(256, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)  # 4 -> 2\n",
    "\n",
    "    # -------------------------\n",
    "    # Block 5\n",
    "    # -------------------------\n",
    "    x = layers.Conv3D(256, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv3D(256, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv3D(256, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv3D(256, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv3D(256, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    # No pooling here (too small after 5th block)\n",
    "\n",
    "    # -------------------------\n",
    "    # Classifier\n",
    "    # -------------------------\n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    x = layers.Dense(512, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"sigmoid\")(x)  # binary\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4816564-06ac-4d2b-946b-ed7834af03a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"/home/m-health/TBM/Lung/\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "strategy = tf.distribute.get_strategy()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Build & compile model\n",
    "\n",
    "# Example usage with TPU/strategy\n",
    "strategy = tf.distribute.get_strategy()\n",
    "with strategy.scope():\n",
    "    model = VGG19_3D_reduced()\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) Callbacks\n",
    "# ------------------------------------------------------------\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.001,\n",
    "    patience=5,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=os.path.join(save_dir, \"VGG19.h5\"),\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6) Train\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=E,\n",
    "    batch_size=BS,\n",
    "    callbacks=[lr_callback, checkpoint_callback],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7) Load best model & evaluate\n",
    "# ------------------------------------------------------------\n",
    "best_model = tf.keras.models.load_model(os.path.join(save_dir, \"VGG19.h5\"))\n",
    "loss, accuracy = best_model.evaluate(X_test, y_test)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8) Predictions\n",
    "# ------------------------------------------------------------\n",
    "predictions = best_model.predict(X_test)\n",
    "predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "class_names = ['benign', 'malignant']\n",
    "print(classification_report(y_test, predicted_classes, target_names=class_names, digits=5))\n",
    "\n",
    "auc = roc_auc_score(y_test, predictions)\n",
    "print(\"AUC:\", auc)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 9) Confusion Matrix\n",
    "# ------------------------------------------------------------\n",
    "cm = confusion_matrix(y_test, predicted_classes)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "print(f'Loss: {loss*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22207c0-462d-4c30-8ceb-4fc4059dba1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
